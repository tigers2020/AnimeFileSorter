좋습니다. 윈도우 전용 독립 실행형 애니메이션 파일 관리 애플리케이션을 설계하고자 하시며, 파일 정리, 플러그인 기반 API 연동, 오프라인 메타데이터 저장, 미디어 플레이어 연동 및 시청 기록, 추천 기능 등을 포함한 전체 개발 계획서를 준비하겠습니다.

파일 구조는 연도 → 분기 → 시리즈명 → 에피소드 파일 순으로 정리되며, Python을 우선 고려하되 성능 또는 GUI 요구에 따라 다른 언어도 평가하겠습니다. GUI는 가장 널리 사용되는 프레임워크 중 하나를 선정할 것입니다.

계획서는 시스템 구성도, 기술 스택, 모듈 설계, 플러그인 설계, API 연동 방식, 데이터베이스 구조, 테스트 및 배포 계획까지 포함하여 준비해드리겠습니다. 완료되면 알려드리겠습니다.


# Windows 전용 애니메이션 파일 정리 애플리케이션 개발 계획서

## 1. 목표

이 프로젝트의 목표는 **Windows 전용 독립 실행형 애니메이션 파일 정리 애플리케이션**을 개발하는 것입니다. 사용자가 로컬에 보유한 애니메이션 동영상 파일들의 폴더를 지정하면, 프로그램이 **외부 메타데이터 API** (예: AniDB, TMDB 등)를 활용하여 각 파일의 애니메이션 정보를 조회하고, **파일을 연도 → 분기 → 시리즈명 → 에피소드 형태의 디렉토리 구조로 자동 정리**해 줍니다. 이를 통해 사용자는 애니메이션 파일을 체계적으로 관리하고, 부가적인 정보(에피소드 제목, 방영일, 썸네일 등)도 함께 활용할 수 있게 됩니다.

## 2. 전체 시스템 구성

애플리케이션은 **GUI 클라이언트** 형태로 제공되며, 내부적으로 파일 식별/정리 로직, 메타데이터 수집 플러그인, 데이터베이스, 미디어 플레이어 연동 모듈로 구성됩니다. 아래 **전체 시스템 구성도**는 주요 구성 요소와 상호 작용을 나타냅니다.

&#x20;*Windows 전용 애니메이션 파일 정리 애플리케이션의 시스템 아키텍처 구성도.* 각 구성 요소는 다음과 같습니다. 사용자 인터페이스(GUI)를 통해 사용자가 폴더를 선택하거나 정리 옵션을 지정하면, **코어 로직**이 해당 경로의 파일을 스캔하여 해시를 계산하고 파일 정보를 추출합니다. 그 후 **메타데이터 플러그인 모듈**을 통해 AniDB, TMDB, MyAnimeList, AniList 등의 외부 API로부터 필요한 **메타데이터 조회 요청**을 보내고, 응답으로 **시리즈 및 에피소드 정보**를 받아옵니다. 가져온 메타데이터는 \*\*로컬 데이터베이스(SQLite)\*\*에 캐시되어 저장되며, 이후 파일을 사용자가 지정한 규칙에 따라 **폴더 생성 및 파일명 변경**을 수행하여 정리합니다. GUI에는 정리 결과(폴더 구조, 에피소드명 등)가 갱신되어 표시됩니다. 사용자가 특정 에피소드를 선택해 **재생**을 요청하면, 코어 로직이 \*\*외부 미디어 플레이어(VLC/MPV)\*\*를 호출하여 영상을 재생하고, 재생 완료 이벤트 등을 다시 코어로 받아와 **시청 기록**으로 DB에 저장합니다. 새로운 파일이 폴더에 추가되는 경우 \*\*파일 시스템 감시 모듈(Watchdog)\*\*이 변화를 감지하여 코어 로직에 통지함으로써, 사용자가 수동으로 명령하지 않아도 자동으로 정리 프로세스를 재실행할 수 있습니다.

## 3. 핵심 기술 스택 및 라이브러리

본 애플리케이션은 **Python**을 주 언어로 개발하는 것을 기본으로 합니다. Python은 풍부한 라이브러리와 생산성으로 인해 요구 기능을 구현하기에 적합하며, 또한 Windows 환경에서의 배포도 비교적 용이합니다. 성능 이슈나 GUI 구현상의 이유로 Python이 부적합하다고 판단될 경우 C# (WPF) 등의 대안을 고려할 수 있지만, 여기서는 Python 기반으로 계획합니다.

* **GUI 프레임워크**: Python 기반 GUI 중에서는 \*\*PySide6 (Qt for Python)\*\*를 사용하는 방향을 우선적으로 검토합니다. PySide6는 Qt6 프레임워크를 Python으로 사용할 수 있게 한 바인딩으로, 상용 소프트웨어에서도 활용될 정도로 **안정적이고 완성도 높은 GUI** 구현이 가능합니다. Qt의 풍부한 위젯과 테마 지원을 통해 현대적인 UI/UX를 구축할 수 있고, Windows뿐만 아니라 추후 Cross-platform 확장성도 확보할 수 있습니다. (대안: C# WPF의 경우 .NET 생태계의 장점이 있으나 Python에서 벗어나게 되고, Electron의 경우 웹 기술을 사용하여 개발할 수 있으나 메모리 사용 등의 부담이 있어 신중한 평가가 필요합니다.)

* **데이터베이스**: **SQLite**를 내장 DB로 사용합니다. SQLite는 별도 서버 없이 파일 기반으로 동작하는 **경량 DB 엔진**으로, Python에 내장된 `sqlite3` 모듈을 통해 바로 사용할 수 있습니다. SQLite는 단일 파일로 데이터를 보관하므로 설치나 설정이 간편하고, Windows 클라이언트 애플리케이션의 로컬 데이터 저장소로 이상적입니다. 추후 사용자 수 증가나 동시접속, 원격 접속 요구가 생길 경우를 대비해 **PostgreSQL** 등으로 마이그레이션할 수 있도록 ORM을 활용하여 추상화할 계획입니다.

* **ORM 및 데이터 액세스**: Python의 **SQLAlchemy**를 사용하여 SQLite DB를 액세스합니다. SQLAlchemy는 ORM(Object-Relational Mapping)을 제공하여 파이썬 객체로 DB를 다룰 수 있게 해주며, 특정 DBMS에 종속되지 않는 코드 작성을 도와줍니다. 이를 통해 SQLite로 개발하더라도, 설정만 바꾸면 PostgreSQL 등으로 이전이 비교적 용이하도록 합니다.

* **메타데이터 조회용 HTTP 클라이언트**: **Requests** 라이브러리를 사용합니다. Requests는 Python에서 HTTP 요청을 간편하게 처리할 수 있는 사실상의 표준 라이브러리로, REST API 호출에 적합합니다. 각종 외부 API (TMDB, AniDB HTTP, AniList GraphQL 등)를 호출하는 데에 활용합니다.

* **파일 시스템 모니터링**: **Watchdog** 라이브러리를 사용합니다. Watchdog은 파일시스템의 변경 사항(생성, 삭제, 수정, 이동 등)을 실시간으로 모니터링할 수 있는 Python 라이브러리로, 백그라운드 스레드로 폴더를 감시하여 새로운 동영상 파일이 추가되거나 이름이 바뀌는 등의 이벤트를 잡아낼 수 있습니다. 이를 이용해 사용자가 지정한 폴더에 변화가 생기면 자동 정리 기능을 트리거하여 **실시간 폴더 동기화**를 구현합니다.

* **해시 연산**: AniDB의 파일 식별에 요구되는 **ED2K 해시**를 계산하기 위해, Python 표준 라이브러리의 `hashlib` (MD4 알고리즘)과 추가 로직을 사용하거나, 오픈소스 구현을 활용합니다. ED2K 해시는 파일을 일정 크기 블록으로 나눈 후 MD4 해시를 여러 번 적용하여 구하는 특수한 해시로, AniDB에서 파일을 식별하는 데 사용됩니다. 멀티스레드로 대용량 파일의 해시를 계산하기 위해 Python의 `concurrent.futures`(ThreadPoolExecutor) 등을 활용하며, 필요 시 C로 작성된 해시 함수를 사용하는 라이브러리를 도입해 성능을 높입니다 (예: `pyed2k` 또는 `hashlib` + `pycryptodome`).

* **미디어 플레이어 연동**: 외부 플레이어인 **VLC** 또는 **MPV**와 연동합니다. 두 플레이어 모두 CLI 인터페이스나 Python 바인딩을 제공하므로, **python-vlc** 또는 **python-mpv** 패키지를 이용해 제어할 수 있습니다. 예를 들어 `python-mpv` 라이브러리는 ctypes를 통해 MPV 플레이어를 제어하여 재생, 일시정지 등을 프로그래밍적으로 다룰 수 있고, JSON IPC를 통해 외부 mpv 프로세스를 통제하는 방법도 있습니다. 이러한 방법을 통해 GUI에서 “재생” 버튼을 누르면 해당 플레이어를 임베드하거나 새 프로세스로 실행하고, 재생 상태를 피드백 받아오는 통합을 구현합니다.

* **기타**: 그 외에도 JSON 데이터 처리를 위한 `json` 모듈, 날짜 및 기간 계산을 위한 `datetime` 및 `pytz`, 로그 기록을 위한 `logging` 모듈 등을 사용합니다. GUI 쓰레딩과 백엔드 작업 분리를 위해 Python의 `threading`이나 PySide6의 `QThread`를 활용하여, 해시 계산이나 API 통신 중에도 UI가 응답성을 유지하도록 합니다.

## 4. 기능별 모듈 설계

요구사항에서 제시된 주요 기능들을 중심으로, 각 기능을 담당할 모듈과 설계 방안을 설명합니다. 모듈별로 책임과 흐름을 명확히 분리하여 유지보수성과 확장성을 높이는 것을 기본 원칙으로 합니다.

### 4.1 파일 해시 기반 에피소드 식별 (AniDB 기반)

**파일 식별 모듈**은 주어진 동영상 파일이 어떤 애니메이션 시리즈의 몇 화인지 식별하는 역할을 합니다. 이를 위해 **해시 기반 식별 알고리즘**을 구현합니다. 구체적으로, **AniDB**에서 사용되는 ED2K 해시를 활용합니다. AniDB는 각 동영상 파일을 ED2K 해시로 **고유 식별**하는 시스템을 갖추고 있으며, 이 해시 값과 파일 크기를 조합하여 AniDB 데이터베이스에서 해당 파일이 어떤 애니메이션의 어떤 에피소드인지 조회할 수 있습니다.

* **ED2K 해시 계산**: 파일을 9,728,000 바이트 청크로 분할하고 각 청크에 MD4 해시를 적용한 뒤, 그 해시들로 다시 MD4 해시를 하는 방식으로 ED2K 해시를 구합니다. 이 과정은 대용량 파일에서도 효율적으로 동작하도록 스트리밍 방식으로 구현하거나, 멀티코어를 활용하여 병렬 처리합니다. 예를 들어 오픈소스로 공개된 `anidbcli` 도구도 멀티코어 ED2K 해싱을 지원하고 있어 이러한 기법을 참고할 수 있습니다.

* **AniDB API 조회**: 해시와 파일 크기 정보를 갖고 AniDB에 조회를 보냅니다. AniDB는 공개 API로 **UDP API**를 제공하며, 파일 해시를 조회하면 해당 파일의 \*\*파일 정보(file info)\*\*를 반환합니다. 이 파일 정보에는 **에피소드 ID**와 **애니메이션 시리즈 ID** 등이 포함되어 있어서, 이를 통해 해당 파일이 어떤 시리즈의 몇 번째 에피소드인지를 알 수 있습니다. AniDB API는 사용 전에 **유저 계정 및 클라이언트 인증**이 필요하므로, 애플리케이션에서 AniDB 클라이언트로 등록하고 사용자에게 AniDB 계정 정보를 받는 과정을 거칠 것입니다. (AniDB는 API 사용량에 엄격한 제한이 있어, 한 계정/IP당 일정량 이상의 요청을 보내면 **BAN** 당할 수 있으므로 주의가 필요합니다. 실제로 AniDB는 하루 250여 개 이상의 파일을 처리하는 경우 차단될 수 있으며, **중복 요청을 피하기 위한 로컬 캐싱**을 강하게 권고하고 있습니다.)

* **파일명 기반 보조 식별** (선택사항): 해시 기반 식별이 실패하거나 AniDB에 없는 파일의 경우, **파일명 파싱**을 통한 보조 식별 로직도 준비합니다. 예를 들어 파일명이 `[SubsPlease] Attack on Titan - 01 [1080p].mkv`와 같은 패턴이라면 정규표현식 등을 통해 시리즈명(`Attack on Titan`)과 에피소드 번호(`01`)를 추출하고, TMDB나 AniList 등의 검색 API를 통해 해당 시리즈를 찾는 방법입니다. 이는 해시 기반 방법보다 신뢰도는 낮지만, 백업 수단으로 유용할 수 있습니다.

* **결과 처리**: AniDB로부터 에피소드 정보(시리즈 ID, 에피소드 번호 등)를 받아오면, 이를 다른 메타데이터 API와 연계하기 위한 키로 활용합니다. 시리즈 ID는 가급적 **공용 식별자**로 변환하거나, 시리즈명을 받아와서 TMDB/MAL 등의 API 호출에 활용합니다. (일부 데이터베이스 간에는 상호 ID 매핑이 존재하기도 합니다. 예를 들어 AniDB와 TheTVDB 간 매핑 파일, AniList와 MAL ID 연계 등이 알려져 있습니다. 필요한 경우 이러한 매핑 데이터를 활용할 것입니다.)

### 4.2 메타데이터 수집 (다양한 API 플러그인 연동)

파일이 어떤 에피소드인지는 AniDB 해시로 확인했다면, **그 이상**의 부가 정보를 얻기 위해 다양한 외부 **메타데이터 API**를 활용합니다. **메타데이터 모듈**은 플러그인 구조로 설계되어, **TMDB**, **AniDB**, **MyAnimeList**, **AniList** 등 여러 출처로부터 정보를 수집하고 통합합니다. 각 API 별로 각각의 플러그인 클래스를 두어 구현하고, 공통된 인터페이스를 통해 필요한 정보를 요청할 수 있게 합니다.

* **AniDB 플러그인**: 파일 식별 단계에서 AniDB로부터 얻은 시리즈 ID, 에피소드 ID 등을 이용하여 **AniDB의 추가 정보**를 가져옵니다. AniDB 자체도 애니메이션의 기본 정보(예: 일본어 제목, 영문 제목, 에피소드 제목 목록, 방영 연도, 화수 등)를 제공하므로, 우선적으로 AniDB를 조회합니다. AniDB UDP API 또는 HTTP API를 사용하며, 파일 식별과 동일한 인증이 필요합니다. AniDB에서 얻은 기본 정보는 신뢰도가 높으며, 특별히 애니메이션에 특화된 데이터(에피소드별 상세 제목, 파일 CRC 등)도 받을 수 있습니다. 다만 AniDB API는 앞서 언급했듯이 호출 제한이 엄격하므로, **필요한 경우에만 조회**하고 결과는 최대한 캐싱합니다.

* **TMDB (The Movie Database) 플러그인**: TMDB는 영화/TV시리즈 DB이지만 유명 애니메이션의 정보도 많이 포함되어 있어, 애니메이션 시리즈의 개요, 포스터 이미지, 제작사, 방영일 등 **풍부한 정보를 REST API로 제공**합니다. TMDB API는 키를 발급받아야 하지만 비교적 사용이 자유로우며, 클라이언트 인증만으로 이용 가능합니다. TMDB 플러그인은 **시리즈명**이나 **AniDB에서 얻은 연도 정보** 등을 사용하여 TMDB의 Search API로 해당 애니메이션을 검색하고, 일치하는 TV 시리즈 ID를 가져온 뒤, **에피소드 목록과 줄거리, 포스터 이미지 URL** 등을 받아옵니다. 이렇게 수집한 정보는 AniDB에서 제공하지 않는 **줄거리 요약, 시리즈 설명, 출연 성우 정보** 등의 부가 데이터로 활용됩니다.

* **MyAnimeList(MAL) 플러그인**: MyAnimeList는 큰 애니메이션 커뮤니티 DB로, 평점, 랭킹, 리뷰 등의 정보가 강점입니다. 그러나 MAL의 공식 API는 OAuth 인증이 필요하고 제약이 많으므로, 본 애플리케이션에서는 **비공식 공개 API인 Jikan**을 사용합니다. Jikan은 MAL 웹사이트를 **크롤링하여 API 형태로 제공하는 서비스**로, MAL에서 공식으로 제공하지 않는 많은 정보를 얻을 수 있습니다. MAL 플러그인은 Jikan의 REST 엔드포인트를 통해 시리즈 검색, 상세 정보, 사용자 평점 등을 가져옵니다. 예를 들어 “원피스”라는 시리즈명을 검색하여 MAL ID를 얻고, 해당 ID로 상세 정보(평점, 장르, 개요 등)를 가져오는 흐름입니다. Jikan은 공개 API이지만 과도한 호출 시 자체 rate limit(분당 60회 등)이 있으므로 적절한 캐싱이 필요합니다.

* **AniList 플러그인**: AniList는 AniDB/MAL과 유사한 애니메이션 DB로서 **GraphQL 기반 API**를 제공합니다. AniList API는 비상업용으로 무료 사용이 가능하며 분당 90회의 쿼리 한도를 가집니다. AniList 플러그인은 Python의 `gql` 라이브러리 등을 활용하여 GraphQL 쿼리를 보내고, 시리즈 및 에피소드 정보를 받아올 것입니다. AniList의 강점은 **유저 선호도 기반 추천, 태그 및 트렌드 정보**인데, 본 프로젝트에서는 주로 시리즈의 **평균 평점, 인기 지표, 태그** 등을 수집하여 활용할 수 있습니다. (예: 태그를 이용해 유사 작품 추천에 활용 가능.)

* **통합 및 충돌 처리**: 서로 다른 출처에서 얻은 메타데이터를 통합할 때 충돌이나 불일치가 발생할 수 있습니다. 예를 들어 AniDB와 TMDB에서 제공하는 에피소드 수나 방영일이 다를 경우 우선순위를 정해야 합니다. 기본적으로 **식별 정보는 AniDB 기준**을 따르고, **사용자에게 표시하는 줄거리나 포스터 등은 TMDB/MAL 등에서 보완**하도록 합니다. 동일한 필드에 대해 여러 소스가 있을 경우 신뢰도나 최신 업데이트 빈도를 고려해 우선순위를 결정합니다. 사용자가 설정에서 특정 소스를 신뢰하도록 우선순위를 커스터마이징할 수도 있게 합니다. 또한 가능한 경우 **여러 출처의 데이터를 모두 표시**하는 것도 방법입니다 (예: AniDB 평균평점 vs MAL 평점 비교 등).

* **플러그인 추가 확장성**: 설계를 플러그인 아키텍처로 함으로써, 향후 **다른 API 연동을 추가**하기 쉽습니다. 예를 들어 **Kitsu** API나 **AnimeNewsNetwork** API 등을 추후 플러그인으로 추가 구현해도 코어 로직을 수정하지 않고 연결할 수 있습니다. 이때 새로운 플러그인은 표준 인터페이스만 구현하고 설정 파일에 등록하면 애플리케이션에 통합됩니다 (플러그인 구조에 대한 자세한 내용은 아래 7장에서 설명합니다).

이러한 멀티-소스 메타데이터 수집을 통해, 프로그램은 **상세하고 풍부한 애니메이션 정보**를 사용자에게 제공합니다. 예를 들어 Shoko라는 오픈소스 애니메이션 관리 프로그램도 AniDB 해시 매칭으로 식별한 후 다른 출처의 메타데이터를 함께 채워 넣는 방식을 취하고 있는데, Shoko는 “파일 해시를 AniDB와 대조하여 정확한 에피소드 식별을 한 다음, 다른 소스에서 메타데이터를 끌어온다”고 소개하고 있습니다. 본 애플리케이션도 동일한 전략을 따라, **정확한 식별 + 풍부한 정보**를 동시에 달성하고자 합니다.

### 4.3 사용자 설정에 따른 파일 정리 (폴더 이동 및 리네이밍)

**파일 정리 모듈**은 식별된 애니메이션 파일들을 사용자 정의 규칙에 맞게 폴더로 이동시키고 파일명을 변경하여 정돈하는 기능을 담당합니다. 기본 정리 규칙은 **“연도/분기/시리즈명/에피소드 번호 – 에피소드 제목”** 형식으로 폴더를 구성하는 것입니다. 예를 들어 “진격의 거인 1화” 영상 파일이 2013년 4월(2분기)에 방영되었다면, 정리 결과로 `2013\2분기\진격의 거인\진격의 거인 - 01화.mkv` 와 같이 배치됩니다. (분기는 1분기=겨울(1~~3월), 2분기=봄(4~~6월), 3분기=여름(7~~9월), 4분기=가을(10~~12월)로 구분하여 사용합니다.)

* **폴더 생성 규칙**: 정리 모듈은 우선 대상 파일의 메타데이터에서 **방영 연도**와 **방영 분기**를 확인합니다. 이 정보는 AniDB나 TMDB에서 얻은 첫 방송일을 기준으로 산출합니다. 해당 폴더 (`연도\분기`)가 없으면 새로 만들고, 그 안에 **시리즈명 폴더**를 생성합니다. 시리즈명은 기본적으로 **국내 방영명**이나 **원제** 중 사용자 설정에 따라 선택할 수 있게 합니다 (예: 국내명 없는 경우 원어명 사용 등).

* **파일명 규칙**: 에피소드 번호 및 제목을 이용하여 파일명을 구성합니다. 에피소드 번호는 두 자리 또는 세 자리 숫자로 포맷하고, 에피소드 제목은 가능하면 짧게 (또는 사용자 옵션으로 포함 여부 결정). 예: "`시리즈명 - 01화.mp4`" 또는 "`시리즈명 - S1E01.mp4`" 등. 사용자가 **파일명 패턴을 커스터마이징**할 수 있도록, 템플릿 문자열을 설정에 두어 `%series%`, `%ep_no%`, `%title%` 등의 플레이스홀더를 지원합니다. (Shoko 등 기존 도구들도 사용자 정의 리네이밍 패턴을 제공하며, 이러한 기능은 파일 정리의 유연성을 높입니다.)

* **관련 파일 처리**: 영상 파일 이외에 같은 이름을 가진 자막 파일(.srt) 등이 있다면, 이동/이름변경 시 함께 처리합니다. 예를 들어 `Attack.on.Titan.S01E01.ass` 자막이 있으면 영상과 동일한 폴더로 옮기고 시리즈명에 맞춰 이름을 변경합니다. 이는 `*.ass`, `*.srt`, `*.sub` 등 **자막/부가 파일 패턴을 사전에 정의**하여 구현하며, 변경 전/후의 매핑을 잘 유지해야 데이터 손실이 없습니다. (Anidbcli 역시 “동일한 이름의 자막 및 기타 파일도 함께 이동/변경” 기능을 제공하는데, 본 애플리케이션도 유사하게 구현합니다.)

* **이름 충돌 및 중복 처리**: 동일한 에피소드 파일이 두 개 이상 있거나(예: 다른 릴 그룹의 중복 에피소드) 이미 해당 경로에 같은 이름의 파일이 존재하는 경우 처리 방법을 정합니다. 일반적으로 중복 에피소드에 대해서는 품질이 더 좋은 파일을 우선 남기고 다른 파일은 별도 폴더(`Duplicates` 등)에 모으는 기능도 고려합니다. 파일 이름 충돌 시에는 `[1]`과 같은 식으로 번호를 붙이거나, 사용자에게 알림을 주어 수동 선택하게 할 수 있습니다.

* **원본 보존 옵션**: 파일 이동 작업은 **위험(파일 손상이나 분실) 방지**를 위해 신중해야 합니다. 기본값으로 **원본 폴더에 대한 백업 옵션**을 제공하여, 이동 작업 이후 일정 기간 원본 위치에 파일을 복사해 두거나, 휴지통으로 보내는 식으로 **실수 복구**를 대비합니다. 또한 정리 작업을 **시뮬레이션 모드**로 실행하여, 실제로 파일을 옮기기 전에 어떻게 구조가 바뀔지 미리 보고 사용자가 확인하도록 하는 기능도 계획합니다.

* **사용자 인터페이스 연동**: GUI에서는 정리 작업의 진행 상황(몇 개 처리되었는지, 현재 이동중인 파일)은 진행바 형태로 보여주고, 완료 후 결과 폴더를 탐색기에서 열어볼 수 있는 버튼을 제공합니다. 특정 시리즈를 선택해서 그 시리즈만 정리하거나, 개별 파일에 대해서 수동으로 경로를 지정할 수 있는 고급 기능도 고려합니다.

이 모듈의 목표는 **사용자 개입 최소화**로 최대한 깔끔한 라이브러리 폴더를 구축하는 것입니다. 결과적으로 사용자는 정돈된 계층 구조 안에서 원하는 애니메이션을 쉽게 찾고 관리할 수 있게 됩니다.

### 4.4 메타데이터 캐싱 및 오프라인 사용 지원

메타데이터 캐싱은 두 가지 목적이 있습니다: **(1) 성능 향상 및 API 호출 제한 대응**, **(2) 오프라인 환경 지원**. 이를 위해 **캐시/DB 모듈**이 존재하며, 앞서 언급한 SQLite DB를 활용합니다.

* **API 응답 캐싱**: 외부 API로부터 불러온 시리즈 정보, 에피소드 정보 등을 로컬 DB에 저장합니다. 기본 키로는 해당 리소스의 고유 ID(AniDB ID, TMDB ID 등)를 사용하고, 응답 JSON 전체 혹은 필요한 필드만 저장합니다. 예를 들어 **AniDB의 시리즈 ID 1234**에 대한 **시리즈 제목/에피소드 목록** 데이터를 DB에 저장해 두었다면, 다음번에 같은 ID를 조회할 때는 API를 부르지 않고 DB에서 불러올 수 있습니다. 이는 AniDB API 정책상 **반복 데이터 요청 시 밴(Ban)** 위험을 피하는 데 필수적입니다. 캐시된 데이터에는 타임스탬프를 두어, 일정 기간(예: 24시간 또는 7일 등) 경과 후에는 자동으로 새로 고침할 수 있도록 합니다. (특히 방영중인 최신 애니메이션의 경우 계속 에피소드가 추가되므로 주기적으로 업데이트 필요.)

* **로컬 DB 구조**: 데이터베이스에는 **Series(애니메이션 작품)** 테이블, **Episode(에피소드)** 테이블, **File(파일)** 테이블 등이 있고, 각 테이블에 메타데이터 관련 필드를 둡니다. 아래는 **DB 스키마의 예시**입니다.

```plaintext
Series table:
- series_id (INT, PK) – 시리즈 내부 식별자
- title (TEXT) – 기본 시리즈명
- title_jp (TEXT) – 일본어 원제
- year (INT) – 첫 방영 연도
- season (TEXT) – 첫 방영 분기 ("1분기", "2분기", ...)
- anidb_id (INT) – AniDB에서의 작품 ID (있을 경우)
- mal_id (INT) – MyAnimeList 작품 ID (있을 경우)
- tmdb_id (INT) – TMDB 시리즈 ID (있을 경우)
- ... (장르, 감독 등 추가 메타데이터)

Episode table:
- episode_id (INT, PK) – 에피소드 내부 식별자
- series_id (INT, FK to Series) – 소속 시리즈
- episode_number (INT) – 작품 내 에피소드 번호
- title (TEXT) – 에피소드 제목
- anidb_ep_id (INT) – AniDB 에피소드 ID (있을 경우)
- airdate (DATE) – 해당 화 방영일
- ... (에피소드 개별 줄거리 등 추가 메타데이터)

File table:
- file_id (INT, PK) – 파일 내부 식별자
- episode_id (INT, FK to Episode) – 대응하는 에피소드
- file_path (TEXT) – 로컬 파일 경로
- ed2k_hash (TEXT) – 파일 ED2K 해시 값
- file_size (INT) – 파일 크기 (바이트)
- resolution (TEXT) – 해상도 (예: 1080p 등)
- codec (TEXT) – 비디오 코덱 (예: H.264 등)
- ... (오디오 트랙 정보 등 옵션)

WatchHistory table:
- history_id (INT, PK) – 시청 기록 ID
- file_id (INT, FK to File) – 시청한 파일
- watched_at (DATETIME) – 시청 완료 시간
- duration (INT) – 시청 소요 시간(초) 또는 진도율
- completed (BOOL) – 끝까지 시청했는지 여부

FavoriteSeries table:
- fav_id (INT, PK)
- series_id (INT, FK to Series) – 즐겨찾기 등록한 시리즈
- note (TEXT) – (옵션) 메모
```

위 스키마는 예시이며, 실제 구현 시에는 ORM 모델로 정의될 것입니다. 캐싱 관련해서 중요한 점은, **외부 API별 데이터**도 저장하는 것입니다. 예를 들어 MAL 평점이나 AniList 인기 순위 등이 시리즈별로 있을 경우, Series 테이블에 컬럼을 추가하거나 별도 테이블로 저장해둘 수 있습니다. 캐시된 데이터에는 마지막 업데이트 시각을 기록하여, 일정 시간이 지나면 자동으로 갱신하거나 사용자가 “새로 고침”할 수 있게 합니다.

* **오프라인 사용**: 일단 한 번 메타데이터가 캐싱되고 나면, 인터넷 연결이 없는 오프라인 상황에서도 최근에 정리한 라이브러리 정보는 계속 표시되고 활용될 수 있어야 합니다. 사용자는 **오프라인 상태**에서도 라이브러리의 목록을 보고, 검색하고, 재생(mark as watched)하는 등 기본 기능을 사용할 수 있습니다. 다만 새로운 폴더 정리나 메타데이터 갱신은 온라인일 때까지 보류하거나, 나중에 일괄 수행하도록 큐에 넣어둘 수 있습니다. (예: 사용자가 오프라인 상태에서 폴더를 지정하면 파일 해시 식별까지만 해두고, 메타데이터는 “나중에 가져오기”로 표시해두는 방식.)

* **메타데이터 업데이트**: 애니메이션의 정보는 시간이 지나면서 바뀔 수 있습니다 (예: 미방영 에피소드 제목이 나중에 채워짐, 또는 잘못된 정보 수정). 정기적으로 혹은 사용자가 원하는 시점에 “메타데이터 갱신” 기능을 통해 모든 시리즈의 최신 정보를 다시 가져와 업데이트할 수 있게 합니다. 이때도 이미 캐시된 데이터와 비교하여 변경된 부분만 갱신하는 방식으로 API 부하를 최소화합니다.

캐싱 전략을 적절히 운용함으로써, AniDB와 같은 서비스의 요청 제한에 걸리지 않으면서 쾌적한 사용자 경험(빠른 응답, 오프라인 사용)을 제공할 수 있습니다. 또한 초기 대량 라이브러리 정리 시 AniDB 요청이 몰리지 않도록, 한 번 조회한 시리즈는 파일 개수만큼 중복 조회하지 않고 한 번만 조회하도록 설계합니다.

### 4.5 미디어 플레이어 연동 (VLC 또는 MPV 통해 재생)

애플리케이션에서 **재생 버튼**을 누르면 지정된 외부 **미디어 플레이어**로 해당 파일을 열어주는 기능을 구현합니다. 또한 가능하면 **재생 상태 정보를 받아와 시청 기록으로 활용**합니다. 이를 담당하는 **플레이어 연동 모듈**의 설계는 다음과 같습니다.

* **외부 플레이어 선택**: 사용자 설정에서 기본 플레이어를 **VLC**나 **MPV** 중 선택할 수 있도록 합니다. (그 외 플레이어도 명령줄 인자가 지원되면 추가 가능하나, VLC와 MPV는 오픈소스이며 제어 API가 잘 갖춰져 있으므로 우선 이 둘을 고려합니다.) 기본값으로 VLC를 사용하도록 하고, 사용자가 시스템에 해당 플레이어를 설치해 두어야 합니다. 설치 경로를 자동 감지하거나 사용자가 지정할 수 있게 합니다.

* **플레이어 실행 방식**: 두 가지 접근을 검토합니다. **(A) 외부 실행:** 단순히 OS 명령으로 VLC 또는 MPV를 실행하면서 파일 경로를 전달하는 방식. 이 경우 구현이 간단하고 호환성이 높지만, 재생 제어나 상태 피드백을 받기가 어렵습니다. **(B) 임베디드/IPC 제어:** PySide6 GUI 창 내부에 플레이어를 임베드하거나, 파이썬 바인딩으로 제어하는 방식. VLC의 경우 `vlc.py` 바인딩을 통해 파이썬 코드에서 VLC player 객체를 생성하고 영상 출력은 별도 창으로 띄울 수 있습니다. MPV의 경우 `python-mpv` 라이브러리를 통해 Qt 위젯 위에 표시하거나, IPC로 통신하면서 숨김 모드로 실행해 제어할 수도 있습니다. 여기서는 구현 난이도를 고려해 **외부 실행 + IPC 제어 혼합** 방안을 사용합니다: 플레이어는 독립 창으로 띄우되, IPC(예: MPV의 `--input-ipc-server` 옵션이나 VLC의 RC (remote control) 인터페이스)로 해당 프로세스와 통신하여 상태를 읽습니다.

* **재생 상태 모니터링**: MPV의 IPC나 VLC의 RC를 통해 **현재 재생 시간, 일시정지/재생 이벤트, 종료 이벤트** 등을 파악할 수 있습니다. 이를 통해 사용자가 에피소드를 끝까지 시청했는지, 중간에 중단했는지 등을 알아낼 수 있습니다. 예를 들어 MPV IPC로 `{ "event": "end-file" }` 이벤트가 오면 해당 파일 재생이 끝났음을 알 수 있습니다. 또는, GUI에서 아예 재생 완료는 체크하지 않고 사용자가 수동으로 "봤음 표시" 버튼을 눌러 시청 완료로 기록하게 할 수도 있습니다. 구현 복잡도를 고려해 초기 버전에서는 **수동 시청 완료 체크**로 두되, 향후 업데이트에서 자동 감지를 추가하는 방향으로 계획합니다.

* **시청 기록 저장**: 재생이 완료되면 **WatchHistory 테이블**에 해당 기록을 추가합니다. 기록에는 에피소드, 시각, 소요시간 등이 포함됩니다. 동시에 Series나 Episode 테이블에 별도의 `watched_flag`나 `last_watched` 필드를 두어, 최근 시청 여부를 빠르게 확인할 수 있게 할 것입니다. GUI에서는 이미 본 에피소드는 아이콘이나 색상으로 표시해서 한눈에 파악할 수 있도록 UX를 제공합니다.

* **플레이어 추가 기능 활용**: VLC와 MPV 모두 자막 자동로딩, 재생 위치 기억, 영상 품질 조정 등의 기능이 있습니다. 이러한 기능들은 대부분 플레이어 자체가 수행하지만, 애플리케이션 차원에서도 지원하면 좋은 것들이 있습니다. 예를 들어 “다음 화 자동 재생” 옵션을 두어 한 화 끝나면 다음 화를 자동으로 여는 기능, 전체 화면/자막 언어 등의 선호 설정을 플레이어 실행 옵션으로 넘기는 것 등이 가능합니다. 이러한 세부 기능은 사용자 편의를 높이는 요소로 고려합니다.

Shoko와 같은 유사 프로그램에서도 VLC/MPV, Kodi 등 여러 플레이어와 연동하여 **어디서든지 시청(Watch Anywhere)** 기능을 강조하고 있는데, 본 애플리케이션도 원클릭으로 재생이 이루어지고 시청 상태까지 관리되는 일원화된 환경을 제공하는 것을 목표로 합니다.

### 4.6 시청 기록 저장 및 통계/분석 기능

**시청 기록 및 통계 모듈**은 사용자의 콘텐츠 소비 패턴을 저장하고 분석하여 유용한 정보를 제공하는 역할을 합니다. 앞서 설명한 대로 각 에피소드의 재생 완료 시점을 **WatchHistory**에 기록하게 되며, 이를 토대로 다양한 통계와 편의 기능을 구현합니다.

* **시청 진행도 표시**: 사용자가 어느 시리즈를 어디까지 보았는지 추적하여 UI에 표시합니다. 예를 들어 특정 시리즈의 경우 “10/24 화 시청 (42%)”처럼 진행도를 보여주고, 마지막으로 본 에피소드 정보를 표시하여 이어보기가 쉽도록 합니다. 에피소드 리스트 뷰에서는 본 화는 체크 표시나 흐린 색으로, 안 본 화는 뚜렷하게 표시하는 등 UI 피드백을 줍니다.

* **간단한 시청 통계**: 데이터베이스의 WatchHistory를 이용해 **통계 정보를 대시보드 형태**로 제공합니다. 예를 들어:

  * 총 시청 에피소드 수, 총 시청 시간 (시간/분 단위 환산)
  * 일별/월별 시청 패턴 (예: 이번 달에 몇 화를 봤는지, 요일별 평균 시청 시간 등)
  * 가장 많이 본 장르, 가장 선호하는 시리즈 (시청 완료한 작품 수, 즐겨찾기 수 등)
    이러한 통계는 차트나 숫자 지표로 시각화하여 사용자에게 재미와 인사이트를 줍니다. 물론 초기 버전에서는 단순 합계 정도로 시작하고, 점차 기능을 늘려갑니다.

* **시청 기록 편집 및 동기화**: 잘못 기록된 시청 내역을 사용자가 수정하거나 삭제할 수 있는 기능을 둡니다. 또한 여러 PC에서 사용한다면 시청 기록을 **내보내기/가져오기**하거나, AniList/MAL 같은 사이트와 **동기화**하는 것도 고려합니다. (예: AniList API를 통해 특정 유저의 현재까지 본 에피소드 목록을 동기화하여 처음 세팅 시 가져오거나, 반대로 우리 앱의 기록을 AniList에 업데이트하는 등. AniList는 사용자별 **시청 상태 동기화 API**를 제공하므로 충분히 가능한 시나리오입니다.)

* **완주 작품 및 즐겨찾기**: 모든 에피소드를 다 본 시리즈는 **완주**로 표시하고, 사용자에게 “축하 메세지”를 주거나 **별도 목록**에 보여주는 등의 재미 요소를 넣을 수 있습니다. 즐겨찾기에 등록한 시리즈의 새 에피소드를 아직 안 봤으면 알려주는 등의 기능도 시청 기록과 연계하여 구현 가능합니다.

* **데이터 분석 확장**: 추후 머신러닝 등을 접목하여 사용자의 시청 기록을 기반으로 **선호 장르 분석**이나 **시청 패턴 분석**을 고도화할 수 있습니다. 예를 들어 늦은 밤에 시청을 많이 한다든가, 특정 스튜디오 작품을 많이 본다든가 하는 것을 자동으로 발견해낼 수 있습니다. 이러한 분석은 추천 시스템과도 연결될 수 있습니다.

### 4.7 즐겨찾기 시리즈 등록 및 추천 시스템 연동

**즐겨찾기(Favorites) 및 추천(Recommendation) 모듈**은 사용자가 특별히 좋아하는 작품을 관리하고, 새로운 작품을 제안해주는 기능을 다룹니다.

* **즐겨찾기 등록**: 사용자 인터페이스에서 어떤 시리즈에 “별표” 아이콘을 누르면 해당 시리즈를 즐겨찾기에 추가합니다. DB의 FavoriteSeries 테이블에 기록되며, 즐겨찾기 목록을 별도로 볼 수 있게 UI에 제공합니다. 즐겨찾기한 시리즈는 검색이나 목록에서 우선 노출하거나, 별도의 **즐겨찾기 섹션**에서 모아볼 수 있습니다. 또한 즐겨찾기 작품에 한해 업데이트 소식을 표시할 수도 있습니다 (예: 아직 방영중인 작품의 새 에피소드 방영일 알림).

* **추천 시스템 연동**: 추천은 내부 알고리즘 또는 외부 API를 통해 구현합니다.

  * **외부 API 활용**: AniList나 MAL 등 일부 서비스는 비공식적으로 “비슷한 작품” 정보를 제공하거나, 유저 기반의 추천 데이터를 가지고 있습니다. 예컨대 AniList GraphQL로 특정 작품의 **유사 태그를 가진 작품**을 질의하거나, MAL에서 **유저 추천(Recommendations)** 페이지를 스크레이핑하는 방법이 있습니다. 또는 **Anime Recommender API**와 같은 공개 API를 활용해 즐겨찾기 작품을 입력하면 비슷한 작품 리스트를 받을 수도 있습니다.
  * **내부 알고리즘**: 간단한 방식으로는, 즐겨찾기한 작품들과 **장르 혹은 태그가 겹치는 다른 인기 작품**을 찾아 추천할 수 있습니다. 우리 DB에 이미 여러 작품의 장르/태그 정보가 수집되어 있으므로, 이를 교집합 분석하거나, AniDB/TMDB 등의 유사 작품 목록을 활용하는 것입니다. 또 하나는 **협업 필터링(collaborative filtering)** 개념을 도입하는 것인데, 이는 많은 사용자 데이터가 있어야 하므로 초기엔 어렵지만, 만약 장기적으로 사용자 커뮤니티 기능이 생긴다면 적용을 고려할 수 있습니다.

* **추천 UI**: 추천된 작품 리스트를 애플리케이션 내에서 보여줄 때, 각 추천이 왜 선정되었는지에 대한 설명(예: “장르가 비슷함”, “당신의 즐겨찾기인 X와 동일 감독” 등)을 함께 표기하면 신뢰도를 높일 수 있습니다. 또한 마음에 들지 않는 추천은 제거하거나, 관심 목록에 추가하는 등의 액션을 제공하여, 사용자의 피드백을 추천 시스템에 반영하도록 합니다 (ex. 추천 결과에서 제외 목록 관리).

* **개인화 설정**: 사용자가 추천 시스템을 원하지 않으면 끌 수 있도록 하며, 추천에 사용할 즐겨찾기 기준도 사용자가 선택하게 합니다. 혹은 특정 즐겨찾기 작품을 기준으로 “이 작품을 좋아한다면...” 식의 추천을 볼 수 있게 UI를 구성할 수도 있습니다.

전반적으로 즐겨찾기/추천 기능은 부가 기능이지만, 애니메이션 감상 경험을 풍부하게 해 줄 수 있는 요소입니다. 특히 많은 작품을 관리하다 보면 새로운 작품을 찾는 것도 중요해지므로, 본 애플리케이션이 **사용자의 애니메이션 큐레이션 도우미**가 될 수 있도록 점진적으로 발전시켜 나갑니다.

## 5. 주요 외부 API 연동 설계

이 섹션에서는 애플리케이션이 통신하게 될 주요 외부 API들(AniDB, TMDB, MAL, AniList 등)의 사용 방식과 요구 사항을 정리합니다. 각 API의 인증 요건과 활용 범위를 파악하여, 안정적인 연동을 도모합니다.

### 5.1 AniDB API

* **API 종류**: AniDB는 주로 **UDP 프로토콜 기반 API**를 제공합니다. XML/JSON HTTP API도 제한적으로 있지만 공식 문서는 UDP 사용을 중심으로 합니다. **AniDB UDP API**를 사용하기 위해서는 클라이언트 식별자(API Key)와 AniDB 사용자 계정 자격증명(유저명/패스워드)이 필요합니다. 이는 AniDB가 비인증형 키보다 사용자 단위로 쿼리를 관리하기 때문인데, 이러한 특성 때문에 FileBot 같은 툴에서도 기본 지원을 꺼리기도 했습니다.

* **인증 및 세션**: 애플리케이션 시작 시 AniDB UDP에 **LOGINS** 패킷을 보내 인증을 수행하고 세션을 받아옵니다. 이후 쿼리 전송 시 해당 세션을 사용하며, 일정 기간 사용 없으면 세션이 만료되므로 필요한 경우 재인증을 합니다. 인증 정보(특히 비밀번호)는 암호화하여 로컬에 저장하거나, 세션 토큰만 저장하고 평문 비밀번호는 저장하지 않도록 유의합니다.

* **요청 종류**: 애플리케이션에서 사용할 AniDB API 요청은 주로 **FILE** (해시로 파일 정보 조회), **ANIME** (애니메이션 ID로 애니 정보 조회), **EPISODE** (에피소드 ID로 에피소드 정보 조회) 등이 있습니다. 첫 단계는 파일 식별을 위한 FILE 요청이며, 응답으로 애니메이션 ID와 에피소드 번호 등을 얻으면, 다음으로 ANIME 요청을 보내 시리즈 정보를 얻습니다. AniDB의 응답 데이터에는 작품의 기본 제목들(메인, 카나, 영어 등), 에피소드 리스트(제목, 방영일), 총 에피소드 수, 카테고리(장르) 등이 포함됩니다. 이를 파싱하여 DB에 저장합니다.

* **Rate Limit 및 Ban 회피**: AniDB는 앞서 말한 대로 엄격한 anti-leech 정책이 있습니다. 구체적으로 “2초에 하나보다 더 빠르게 요청을 보내지 말 것”, “동일 데이터를 반복 요청하지 말 것” 등이 있습니다. 이를 위해 **로컬 캐싱**은 필수이며, 여러 파일이 동일 시리즈에 속해 있으면 한 번만 시리즈 정보를 받아서 공유합니다. 또한 다수 파일 해시 조회 시 요청을 **Queue**에 넣고, 내부적으로 2초 딜레이를 지켜가며 순차 처리합니다. 만약 일정 수 이상의 요청으로 IP Ban이 걸릴 경우를 대비해, 애플리케이션에 **대기 및 재시도 로직**을 추가합니다 (ex. Ban 징후 감지 시 사용자에게 알리고 30분 후 자동 재시도).

* **기술 구현**: Python에서는 UDP 소켓 프로그래밍으로 직접 구현할 수도 있고, 앞서 검색한 `pyanidb`나 `anidbcli`의 일부 코드를 참고하여 UDP 프로토콜을 처리할 수 있습니다. 패킷 조립과 파싱에 주의해야 하며, 특히 UTF-8 문자열 처리를 제대로 해야 일본어 등의 데이터가 깨지지 않습니다. UDP이므로 패킷 유실 가능성도 있어, 타임아웃 후 재요청 처리도 넣습니다.

* **기타 활용**: AniDB API로 **이미지**(예: 애니메이션 포스터나 스크린샷)는 제공되지 않으므로, 이미지 관련해서는 TMDB 등의 데이터를 사용하게 될 것입니다. AniDB로부터는 텍스트 기반 정보 위주로 활용하고, AniDB 고유의 **Mylist** 기능(사용자 소장 리스트 관리)은 본 애플리케이션에서는 사용하지 않습니다(클라이언트로 AniDB MyList에 추가하는 API도 있지만, 우리 앱은 로컬 관리 목적이므로 굳이 AniDB 계정에 소장 데이터를 보낼 필요는 없습니다).

### 5.2 TMDB API

* **API 개요**: TMDB (The Movie Database)는 영화 및 TV 시리즈에 대한 방대한 정보를 가진 공개 DB로, **RESTful HTTP API**를 제공합니다. API 사용을 위해 TMDB 사이트에서 발급받은 **API Key**가 필요하지만, OAuth 등의 추가 인증은 요구하지 않습니다. API Key는 우리 애플리케이션에 내장하거나(클라이언트에서 숨기기 어렵다면 사용자로부터 입력받게 할 수도 있습니다) 앱 설정에 저장해두고 모든 요청에 `api_key` 파라미터로 포함하여 사용합니다.

* **요청 시나리오**: TMDB에서 애니메이션 정보를 얻는 주요 방법은 두 가지입니다:

  1. **Search API**: 애니메이션 **시리즈명을 검색**하여 TMDB의 시리즈 ID를 얻습니다. (엔드포인트: `/search/tv?query={name}` 등)
  2. **TV Details API**: 시리즈 ID를 안다면 해당 시리즈의 상세 정보와 에피소드 정보를 조회합니다. (`/tv/{series_id}` 및 `/tv/{series_id}/season/{season_number}` 등)

  애니메이션은 TMDB에서 보통 TV Series로 취급되며, 시즌/에피소드 구조로 되어 있습니다. 일본 애니메이션의 경우 보통 Season 1로 전체를 묶거나, 여러 기수(쿨)를 시즌1,2,...로 구분하기도 합니다. 이 점을 감안하여, 검색 결과를 매칭할 때 연도나 부제 등을 함께 고려합니다 (예: “Naruto” 검색 시 “Naruto Shippuden”과 구분 필요).

* **수집 데이터**: TMDB로부터 가져올 데이터는 **포스터 및 배너 이미지 URL**, **개요(description)**, **장르 정보**, **에피소드 러닝타임**, **제작사 정보** 등이 있습니다. 또한 에피소드별로 **에피소드 제목, 줄거리, 방영일**을 가져올 수 있습니다. 이 데이터들은 AniDB에는 없거나 영어로만 있을 수 있는 정보이므로, UI 표시용으로 유용합니다. 이미지의 경우 URL만 저장하고 실제 다운로드는 사용자가 볼 때 로드하거나, 캐싱 전략에 따라 썸네일은 미리 받아둘 수도 있습니다.

* **언어 설정**: TMDB API는 `language` 파라미터를 지원하여, 현지화된 데이터(예: 한국어 제목/개요)가 있을 경우 받을 수 있습니다. 한국 사용자라면 `"language=ko-KR"`로 요청하여 한글 데이터가 있으면 받도록 하고, 없을 경우 대비해 기본 영어 데이터를 함께 저장합니다. 다만 애니메이션의 한글 개요는 완비되지 않은 경우가 많으므로, 이중 언어 처리를 고려합니다.

* **요청 제한**: TMDB API의 이용 제한은 비교적 관대한 편입니다. 일정 시간당 요청 횟수 제한이 있으나 (예: 40/request per 10 seconds 등), 캐싱과 병합 요청으로 충분히 회피 가능할 것입니다. 대량 데이터의 경우 한 번에 여러 페이지를 가져와야 하는데, 이럴 때 타임슬립을 걸어둡니다. TMDB 측 정책상 API Key는 클라이언트에 노출될 수 있으므로, 악용되지 않도록 주의만 하면 됩니다.

* **TMDB와 AniDB 데이터 연계**: 혹시 AniDB의 데이터에 TMDB ID 매핑이 있는 경우 바로 활용할 수 있지만, 일반적으로는 없으므로 시리즈명으로 검색하게 됩니다. 그러나 **Shoko 등 일부 시스템은 AniDB와 TVDB/TMDB 간 매핑**을 내장하기도 하는데, 우리도 향후 오픈소스 매핑 데이터를 확보하면 사용하여, 검색 오류를 줄이고 바로 ID를 얻을 수 있을 것입니다.

### 5.3 MyAnimeList (MAL) / Jikan API

* **API 종류**: MyAnimeList는 공식 API (v2)가 존재하지만, OAuth2 인증을 요하는 사용자 전용 API이고 공개 애니 데이터 접근에 제약이 있습니다. 따라서 본 프로젝트에서는 **Jikan API**를 사용합니다. Jikan은 **비공식 공개 REST API**로, MyAnimeList 웹사이트의 공개 데이터를 **스크레이핑하여 JSON 형태로 제공**합니다. 버전 4 기준으로 `https://api.jikan.moe/v4` 아래 다양한 엔드포인트를 제공합니다.

* **데이터 수집 내용**: MAL은 **유저 평점**, **순위(rank)**, **인기도(popularity)** 등의 커뮤니티 지표를 가지고 있고, **태그 기반 분류** (예: “isekai”, “vampire” 등 이용자 지정 태그)가 풍부합니다. 우선 각 시리즈의 \*\*평균 평점(score)\*\*과 **인기도 순위**를 가져와 Series 테이블에 저장합니다. 또한 **장르**와 **테마 태그** 목록도 MAL이 제공하므로, 이 데이터를 활용해 장르 필드를 채우거나 내부적으로 태그 기반 추천에 쓰겠습니다. 에피소드 상세 정보는 MAL에서는 유료회원에게만 제공하므로 시리즈 단위 정보 중심으로 사용합니다.

* **엔드포인트 사용 예**:

  * 작품 검색: `/anime?q={query}` (예: `/anime?q=Naruto` → 여러 결과 중 “Naruto Shippuden” 확인)
  * 작품 상세: `/anime/{mal_id}` (예: `/anime/20` → “Naruto Shippuden” 상세 JSON)
  * 작품 추천: `/anime/{mal_id}/recommendations` (이 작품을 본 유저들이 추천한 다른 작품 리스트)
  * 작품 리뷰, 에피소드, 캐릭터정보 등도 엔드포인트가 있지만 우선은 필요 없음.

* **Rate Limit**: Jikan은 공개 API지만 분당 60회, 초당 3회 등의 제한이 있습니다. 이는 AniDB만큼 엄격하지 않으나, 여전히 대량 호출 시에는 캐싱과 간격 조정이 필요합니다. 본 애플리케이션은 Jikan 데이터를 캐싱하므로 일반적인 사용에서는 제한에 걸릴 가능성이 낮습니다. 또한 Jikan 쪽에서 MyAnimeList 차원에서의 rate limit에 걸릴 수 있다고 언급하므로, 한번 가져온 데이터는 24시간 캐시하는 그들의 정책에 따르게 됩니다 (Jikan은 자체적으로 24시간 캐시를 운영하므로 연속 요청 시에도 같은 응답을 주게 됩니다).

* **주의사항**: Jikan은 스크레이핑 기반이라 MAL 사이트 구조 변화 시 동작이 불안정해질 수 있습니다. 이를 대비해 Jikan API가 실패할 경우 대비책(예: AniList로 대체 조회나, 캐시된 마지막 정보 사용)을 마련합니다. 또한 MAL ID를 AniDB나 AniList ID로부터 얻는 매핑은 없으므로, 시리즈명을 통해 검색해야 하고, 동명 이작품 구분을 위해 연도 등의 정보를 함께 고려해야 합니다. (예: “Fate/stay night” 시리즈는 리메이크 등 여러 버전 존재).

### 5.4 AniList API

* **API 종류**: AniList는 **GraphQL API**만을 공식 지원합니다. GraphQL은 단일 엔드포인트(`https://graphql.anilist.co` 등)에 쿼리를 보내는 방식이며, REST 대비 한 번 요청으로 다량의 관련 데이터를 효율적으로 가져올 수 있는 장점이 있습니다. AniList API 사용을 위해 별도의 키는 필요 없으나, 너무 많은 요청을 보내면 IP 제한이 있을 수 있어 권장 제한인 **분당 90회** 내로 사용해야 합니다. GraphQL 특성상, 요청당 데이터량에 따라 실제 부하가 결정되므로, **필요한 필드만 선택**하는 최적화가 중요합니다.

* **활용 방안**: AniList는 AniDB나 MAL과 데이터 중복이 많지만, **유저 관심도 데이터와 관계 데이터**(예: 비슷한 작품, 동일 스튜디오 작품, 제작진 정보)가 잘 되어 있습니다. 굳이 AniList까지 필요한가 고려할 수 있지만, *“있으면 좋은”* 기능 몇 가지를 위해 연동합니다:

  * **추천 작품**: AniList에는 특정 작품을 좋아하는 사람들이 좋아하는 다른 작품 리스트를 추출하는 쿼리를 작성할 수 있습니다. (직접적인 추천 API는 없지만, GraphQL로 사용자나 좋아요 데이터를 조합하는 식)
  * **트렌드**: 현재 인기있는 작품 (방영중인 애니 중 댓글수 상위 등) 데이터를 가져와 “요즘 화제작” 섹션을 꾸밀 수 있음.
  * **캐릭터 및 성우 정보**: AniList는 캐릭터와 성우 데이터도 제공하므로, 작품 상세 페이지에 부가 정보를 표시할 수 있음.

  우선 버전에서는 필수는 아니므로, AniList 플러그인은 **낮은 우선순위**로 개발하거나, 또는 AniList와 MAL 중 하나만 선택하려면 MAL(Jikan)을 우선하고 AniList는 보류할 수 있습니다.

* **구현**: Python에서 `gql`이나 `requests`로 GraphQL 쿼리를 보내면 됩니다. 쿼리 예시는 다음과 같습니다 (작품 검색 및 기본정보 조회):

  ```graphql
  query ($name: String) {
    Media(search: $name, type: ANIME) {
      id
      title {
        romaji
        english
        native
      }
      status
      episodes
      averageScore
      genres
    }
  }
  ```

  이를 호출하면 주어진 이름에 가장 가까운 애니메이션의 ID, 제목(로마지/영문/원문), 방영상태, 총 에피소드 수, 평균점수, 장르 목록을 얻을 수 있습니다. 이후 ID로 **추천** 쿼리를 날리거나 **트렌드** 쿼리를 날려볼 수 있습니다.

* **제한**: AniList API도 Abuse 시 차단될 수 있으므로, 필요한 경우 GraphQL 쿼리를 합쳐서 보내거나, 캐싱을 적극 활용합니다. AniList ID와 다른 DB의 ID 간 매핑은 공개된 것이 없지만, AniList의 Media 객체 안에 `idMal` 필드로 MAL ID가 제공됩니다. 따라서 MAL ID를 알면 AniList 쿼리를 통해 대응 AniList 데이터를 가져올 수도 있습니다. 이처럼 데이터 소스들 간의 연결고리를 최대한 활용하여 불필요한 검색을 줄입니다.

요약하면, **AniDB**는 정확한 식별과 기본 정보 제공자, **TMDB**는 시각적/스토리 정보 제공자, **MAL/AniList**는 평점/커뮤니티 정보 및 추천 기능의 보조 역할로 각각 포지셔닝하여, 여러 소스의 장점을 취합하는 방향으로 API 설계를 진행합니다.

## 6. 데이터베이스 스키마 상세 및 예시

앞서 4.4절에서 데이터베이스 스키마 예시를 제시하였으며, 여기서는 그 설계를 조금 더 상세히 설명합니다. 데이터베이스는 SQLite를 사용하며, SQLAlchemy ORM으로 매핑하여 다룹니다. 주요 엔티티(테이블)와 관계는 아래와 같습니다:

* **Series (시리즈 테이블)** – 애니메이션 작품 단위로 1개 레코드.

  * *주요 필드*: `id` (PK), `title`, `title_jp`, `year`, `season`, `anidb_id`, `mal_id`, `tmdb_id`, `average_score`, `genres`, `plot_summary` 등.
  * *설명*: 작품의 기본 정보와 외부 참조 ID들을 저장. `anidb_id` 등이 있는 경우 해당 ID로 API 재조회 없이 정보를 보강할 수 있음. `average_score`는 MAL이나 AniList의 평균 평점, `genres`는 장르 리스트 (콤마 구분 문자열 또는 별도 SeriesGenre 테이블로 정규화). `plot_summary`는 TMDB의 개요(한글이 있으면 한글로).

* **Episode (에피소드 테이블)** – 각 애니메이션의 화별 정보.

  * *주요 필드*: `id` (PK), `series_id` (FK, Series), `number` (에피소드 번호, 일부 SP나 번외는 0 또는 101 등으로 표시), `title` (에피소드 제목), `airdate` (방영일), `anidb_ep_id`, `file_count` (이 에피소드와 매칭된 파일 개수) 등.
  * *설명*: 에피소드 하나당 레코드. 보통 1화,2화,... 순으로 번호 매기며, 번호 대신 `code` 필드를 별도로 두어 “OVA”나 “SP”같이 특수코드를 저장할 수도 있음. `file_count`는 한 에피소드에 다수 파일이 링크될 수 있어서 (예: 자막 다른 버전), 이를 갯수로 표시하거나, 혹은 File 테이블에서 COUNT 할 수도 있음.

* **File (파일 테이블)** – 실제 디스크상의 파일 정보와 에피소드의 연결.

  * *주요 필드*: `id` (PK), `episode_id` (FK, Episode), `path` (파일 경로 또는 파일명), `ed2k_hash`, `size`, `quality` (화질, 해상도), `codec`, `last_modified` 등.
  * *설명*: 하나의 에피소드가 여러 파일로 존재할 수 있으므로 (예: 자막 다른 릴, 블루레이판 등), 각각을 구분해 관리. `path`는 정리 후의 위치로 업데이트 되며, 정리 전 원래 경로는 별도로 저장하지 않을 예정 (필요하다면 `original_path` 필드 둘 수도). `quality`나 `codec` 등은 FFmpeg 등으로 파일 분석하여 저장할 수 있으나, MVP에서는 생략 가능.

* **WatchHistory (시청 기록 테이블)** – 파일 단위 시청 기록.

  * *주요 필드*: `id` (PK), `file_id` (FK, File), `watched_at` (DATETIME), `duration` (INT, 재생 시간(초)), `completed` (BOOL).
  * *설명*: 한 파일(에피소드)을 시청한 기록을 남김. 한 에피소드를 여러 번 보면 여러 기록이 쌓일 수 있음. 최근 본 시각 등의 정보를 Episode나 Series에도 denormalization해서 가질 수 있음 (예: Series.last\_watched 등).

* **FavoriteSeries (즐겨찾기 테이블)** – 사용자가 즐겨찾기한 작품 목록.

  * *필드*: `id` (PK), `series_id` (FK, Series), `marked_at` (DATETIME).
  * *설명*: 다대다의 단순화 형태로, 유저가 한 명이므로 Series에 체크해도 되지만 확장성을 위해 별도 테이블로 둠. 현재는 단일 사용자 환경이므로 user\_id 같은 건 없음.

이상의 스키마로 기본적인 기능은 충실히 지원되며, 추후 기능 확장 시 테이블 추가 또는 컬럼 추가를 통해 대응합니다. 예를 들어 **인물(캐릭터/성우)** 테이블을 추가하거나, **시리즈 간 연관관계**(프리퀄/시퀄)를 저장하는 테이블을 둘 수도 있습니다. SQLite는 스키마 변경이 다소 제약이 있지만, SQLAlchemy를 통해 변경 스크립트를 적용하거나, 버전 업 시 마이그레이션 절차를 두는 등으로 대응 가능합니다.

특히 **성능** 면에서, 파일 수천 개, 시리즈 수백 개 정도에서는 SQLite로도 충분히 커버됩니다. 테이블에 적절한 인덱스를 추가하여 (예: File.ed2k\_hash에 인덱스 -> 해시 조회 속도 향상, Episode.series\_id 인덱스 -> 시리즈 별 에피소드 나열 속도 향상 등) 쿼리 성능을 최적화합니다. 또한 ORM 사용 시 한번에 너무 많은 객체를 로딩하지 않도록 (lazy loading 활용) 유의합니다.

## 7. 플러그인 구조 및 확장 설계

메타데이터 수집과 파일 리네이밍 등을 유연하게 지원하기 위해 본 애플리케이션은 **플러그인 아키텍처**를 채택합니다. 플러그인은 **외부 API 연동**, **파일 이름 패턴 정의**, **커스텀 동작** 등을 손쉽게 추가하거나 변경할 수 있도록 합니다. 이 섹션에서는 플러그인의 구조와 동작 방식, 그리고 새로운 플러그인 등록 절차에 대해 설명합니다.

* **플러그인 인터페이스 설계**: 애플리케이션 코어는 플러그인에 대해 기대하는 동작을 **인터페이스 (또는 추상 베이스 클래스)** 형태로 정의합니다. 예를 들어 메타데이터 소스를 위한 `MetadataPlugin` 인터페이스를 정의하고, 여기에 `search_series(title) -> series_id` , `get_series_info(series_id) -> SeriesData`, `get_episode_info(series_id, ep_number) -> EpisodeData` 등의 메서드를 규정합니다. AniDB, TMDB, MAL, AniList 각 플러그인은 이 인터페이스를 구현하여, 코어가 동일한 방식으로 메서드를 호출하더라도 각각 알아서 해당 API를 호출하고 결과를 반환하도록 합니다. Python에서는 `abc` 모듈로 추상클래스를 정의하거나, 혹은 간단히 필요한 메서드 이름만 약속하여 duck typing으로 구현할 수도 있습니다.

```python
# 예시: MetadataPlugin 추상 클래스
from abc import ABC, abstractmethod

class MetadataPlugin(ABC):
    @abstractmethod
    def search_series(self, title:str, year:int=None) -> dict:
        """제목 (및 선택적 연도)을 받아 시리즈 정보 반환 (없으면 None)."""
        pass

    @abstractmethod
    def get_series_info(self, id:str) -> dict:
        """시리즈 ID를 받아 상세 정보를 딕셔너리로 반환."""
        pass

    @abstractmethod
    def get_episode_info(self, series_id:str, ep_number:int) -> dict:
        """특정 시리즈의 에피소드 번호에 해당하는 에피소드 정보 반환."""
        pass
```

위 인터페이스를 구현한 AniDBPlugin, TMDBPlugin 등 클래스를 각각 만들고, 필요한 필드를 딕셔너리나 dataclass 형태로 반환하도록 합니다. 반환된 딕셔너리는 공통 키를 가지며, 예를 들어 `{'id': 'TMDB:12345', 'title': '진격의 거인', 'episodes': [...], 'year': 2013, 'season': 2, ...}` 이런 식으로 통일합니다. 통합은 코어에서 담당합니다.

* **플러그인 로딩 메커니즘**: 플러그인은 **동적 로딩**이 가능하도록 설계합니다. 이를 위해 두 가지 방법을 고려합니다:

  1. **엔트리 포인트 기반 로딩**: Python 패키지 배포 메커니즘에서 setup.py의 `entry_points`를 사용하면, 특정 그룹의 플러그인을 자동으로 인식할 수 있습니다. 예를 들어 `entry_points={'anime_manager.plugins': ['AniDB=plugins.anidb:AniDBPlugin']}` 식으로 작성하고, 코어에서 `importlib.metadata.entry_points()`로 불러오면 설치된 플러그인 모듈들을 가져올 수 있습니다. 이 방식은 플러그인을 독립적인 패키지로 배포할 수 있게 해줍니다.
  2. **플러그인 디렉토리 스캔**: 애플리케이션 폴더 내 `plugins` 디렉토리에 있는 모든 `*.py` 파일을 임포트하여 일정 네이밍 규칙 (예: `XxxPlugin` 클래스)으로 플러그인을 찾습니다. 예를 들어 `plugins/anidb_plugin.py` 내에 `AniDBPlugin` 클래스가 있고 `MetadataPlugin`을 상속한다면 이를 등록합니다. 이 방식은 구현이 간단하나, 별도 배포된 플러그인을 사용자가 추가하려면 해당 폴더에 직접 파일을 넣어야 합니다.

  초기 버전에서는 간단한 **디렉토리 스캔 방식**을 채택하고, 추후 사용자/3rd-party 플러그인 생태계가 필요할 정도로 발전하면 엔트리 포인트 방식을 병행합니다.

* **플러그인 등록 및 설정**: 어떤 플러그인을 사용할지 설정할 수 있도록, 환경설정 파일(e.g., `config.yaml`)이나 GUI 설정 화면에서 플러그인 On/Off 및 우선순위를 관리합니다. 예를 들어 TMDB와 AniList 둘 다 시리즈 정보를 가져올 수 있지만, **시리즈 설명은 TMDB 우선, 평점은 MAL 우선** 등의 정책을 정합니다. 이러한 설정은 코어의 메타데이터 통합 로직에 반영되어, 각 필드별 우선 소스를 결정짓거나, 혹은 첫 성공 응답을 준 플러그인 것으로 설정하는 등 동작하게 합니다. 또한 AniDBPlugin처럼 필수적으로 항상 켜져야 하는 플러그인은 끌 수 없도록 할 수 있습니다.

* **플러그인 간 의존성**: 이상적으로 플러그인은 서로 독립적으로 동작하지만, 약간의 연계는 고려합니다. 예를 들어 AniDBPlugin이 파일 해시를 통해 `series_id`를 반환하면, TMDBPlugin은 그 시리즈명을 사용하여 TMDB 검색을 하는 식으로 **연쇄 호출**이 일어납니다. 이를 코어 로직에서 조율해도 되지만, 플러그인 내부에서 다른 플러그인을 호출하지 않도록 합니다 (의존성 엉킴 방지). 대신 코어가 흐름 제어를 합니다. 즉, AniDBPlugin.identify() → 결과로 시리즈명 얻음 → TMDBPlugin.search\_series(시리즈명) → TMDBPlugin.get\_series\_info(ID) → AniListPlugin.get\_series\_info(ID) ... 이런 순서를 코어에서 orchestrate합니다.

* **파일 정리 플러그인**: 플러그인 아키텍처는 메타데이터 뿐 아니라, **파일 이름 패턴이나 정리 방식**을 커스터마이즈하는 데에도 적용할 수 있습니다. 예를 들어 사용자가 특별한 폴더 구조를 원한다면, `OrganizerPlugin` 형태로 플러그인을 만들어 해당 로직을 구현하게 할 수 있습니다. 기본 구조(연도/분기)는 내장으로 제공하고, 고급 사용자들은 자신의 스크립트를 만들어 플러그인으로 추가할 수 있게 하는 구상입니다. 다만 초기 버전에서는 복잡도를 줄이기 위해 파일 정리 로직은 고정하고, 메타데이터 부분만 플러그인화합니다.

* **테스트 및 샌드박스**: 플러그인은 외부 API를 다루므로, 오용 시 예측하지 못한 동작이나 과도한 요청을 보낼 위험도 있습니다. 따라서 플러그인 별로 **사용량 제한**을 코어에서 감시하고, 에러 발생 시 코어가 예외를 처리하여 전체 프로그램이 안정적으로 동작하도록 해야 합니다. 각 플러그인의 메서드 호출은 try-except로 감싸서 실패한 플러그인을 건너뛰고 로그를 남기며, 사용자에게는 해당 소스에서 데이터를 못 가져왔다는 정보만 알리면 됩니다.

플러그인 구조를 통해 **유연성**과 **확장성**을 확보할 수 있습니다. 새로운 애니메이션 데이터 소스(API)가 등장하거나, 혹은 사용자가 자기만의 데이터 소스를 쓰고 싶을 때, 이 구조 안에 쉽게 편입할 수 있을 것입니다. 예를 들어 국내 사용자들을 위해 **애니메이션 자막 팀 데이터**나 **국내 방영 정보 API**를 플러그인으로 추가하는 것도 가능해질 것입니다.

## 8. 테스트 전략

개발한 애플리케이션이 올바르고 견고하게 동작하도록 하기 위해 **다양한 수준의 테스트**를 수행합니다. 테스트는 유닛 테스트, 통합 테스트, UI 테스트, 성능 테스트로 나눠 진행합니다.

* **유닛 테스트 (Unit Tests)**: 각각의 모듈 (해시 계산, 개별 플러그인, DB 매퍼, 파일 이름 변환 등)에 대해 단위 테스트를 작성합니다. Python의 `pytest` 프레임워크를 사용하여, 예를 들어:

  * ED2K 해시 계산 함수에 known-value 테스트 (작은 파일의 ED2K 해시를 수작업으로 구해놓고 함수 출력과 비교).
  * 파일 이름 파싱 로직 테스트 (여러 형태의 파일명을 입력하여 시리즈명과 화수를 정확히 뽑는지 검증).
  * DB ORM 모델 테스트 (객체 저장/조회 동작 검증, 제약 조건 테스트).
  * 플러그인 메서드 테스트: 실제 API 호출을 직접 하지 않고 \*\*모의 객체(Mock)\*\*나 **vcr.py** 같은 HTTP 인터셉터를 써서 정해진 응답을 돌려주도록 한 후, 파싱 로직이 잘 작동하는지 확인합니다. (API 키 등이 필요한 경우 별도 환경변수 세팅 후 진행하거나, Public한 테스트 ID로 한정)

* **통합 테스트 (Integration Tests)**: 전체 시스템의 주요 시나리오를 통합적으로 테스트합니다. 예를 들어, \*\*시나리오: “특정 폴더에 있는 파일들 정리”\*\*의 경우:

  1. 테스트용 폴더에 여러 파일을 준비 (의도적으로 다양한 케이스: AniDB에 존재하는 파일, 이상한 이름 파일, 중복 파일 등).
  2. 애플리케이션의 코어 로직을 해당 폴더에 대해 실행.
  3. 결과로 생성된 DB와 폴더 구조를 확인:

     * DB에 모든 시리즈/에피소드/파일이 예상대로 입력되었는지.
     * 실제 파일이 옮겨졌는지, 이름이 올바른지.
     * 로그나 메시지에 오류는 없는지.
       이러한 통합 테스트는 실제 API에 연결해서 수행할 수도 있지만, 자동화 환경에서 외부 API에 너무 의존하면 오작동할 수 있으므로, 가능하면 **캐시된 응답**이나 **로컬 서버**를 흉내내어 진행합니다. (예: AniDB UDP 서버를 Mock으로 흉내내거나, TMDB API 응답 JSON을 저장해 사용)

* **GUI 테스트**: GUI는 자동화 테스트가 어려운 부분이 있으나, Qt(PySide6)의 경우 Signal/Slot을 이용해 시뮬레이션이 가능하고, 또 Selenium 같은 툴로 UI를 조작할 수도 있습니다. 우선은 개발 단계에서 **수동 테스트**를 위주로 하고, 중요 로직은 View와 분리되어 있으므로 유닛/통합 테스트로 신뢰성을 담보합니다. 이후 안정화 단계에서 Qt의 `QTest` 모듈 등을 활용해 가상으로 버튼 클릭, 리스트 선택 등을 시뮬레이션하고 결과 상태(DB나 로그 변화)를 검증하는 자동화도 검토합니다.

* **성능 및 부하 테스트**: 라이브러리에 수천 개의 파일이 있을 때 초기 스캔 및 정리 시간이 얼마나 걸리는지 측정합니다. 예를 들어 1000개의 파일(약 1TB 데이터)에 대해 정리 작업을 돌렸을 때, 해시 계산에 수 분, API 호출에 수 분 등 전체 소요 시간을 추산하고, 메모리 사용량도 모니터링합니다. SQLite 접근이 병목되지 않도록 인덱스 튜닝 여부를 여기서 판단합니다. 또한 Watchdog로 지속 감시할 때 CPU 점유율이 미미한지, GUI 스레드와 작업 스레드 간 데드락이나 리소스 경합이 없는지도 확인합니다.

* **사용자 인수 테스트 (UAT)**: 내부적으로 충분히 테스트한 후, 베타 버전을 소수의 사용자(예: 개발팀 내 혹은 관심있는 지인)에 제공하여 **실제 시나리오 테스트**를 받습니다. 사용자의 실제 애니메이션 폴더를 대상으로 실행해보고, 예상치 못한 상황(특이한 파일명, 네트워크 불안정 등)에서의 문제를 피드백받아 수정합니다. 특히 한국 사용자의 패턴 (한글 파일명, 멀티 자막 등)에 특화된 조정도 이 단계에서 반영합니다.

* **테스트 환경**: 개발 중에는 Windows 10/11 환경에서 테스트하며, CI(Continuous Integration) 환경에서는 Windows Runner를 사용해 pytest를 돌립니다. CI에서 실제 API 호출 테스트는 키 관리 문제로 제외하거나 read-only 테스트만 수행하고, 로컬에서 통합 테스트는 주기적으로 수동으로 돌려봅니다.

테스트를 충분히 거침으로써, 릴리스 시 주요 기능들이 의도대로 작동하고, 오류 상황에서도 프로그램이 안정적으로 (크래시 없이) 대응할 수 있도록 합니다. 특히 파일 이동/삭제와 같은 **파괴적인 작업의 신뢰성**이 핵심이므로, 이를 위한 시뮬레이션 모드와 백업 기능을 실제 테스트해 검증하는 것이 중요합니다.

## 9. 배포 및 유지보수 전략

마지막으로, 완성된 프로그램을 사용자에게 배포하고 향후 유지보수/업데이트하는 전략입니다. Windows 전용 애플리케이션이므로 Windows 환경에 최적화된 배포 방식을 고려합니다.

* **배포 형식**: Python으로 개발되었지만, **Standalone 실행 파일 (.exe)** 형태로 배포하여 사용자가 Python 환경을 직접 건드릴 필요 없도록 합니다. `PyInstaller`를 사용하여 모든 의존 라이브러리와 Python 인터프리터를 포함한 실행 파일을 생성합니다. PyInstaller를 통해 single-folder 모드(여러 파일 묶음)나 one-file 모드(압축된 단일 exe)로 만들 수 있는데, 용량은 증가해도 편의성을 위해 **일체형 실행 파일**로 제공하는 것을 고려합니다. 이 때 VLC나 MPV 등의 외부 프로그램은 사용자에게 별도 설치를 요구할 수 있으므로, 만약 portable VLC를 함께 번들링하려면 라이선스 검토가 필요합니다 (VLC is LGPL, bundling is allowed as long as license is included).

* **인스톨러 제공**: 사용 편의를 위해 Inno Setup이나 NSIS를 이용해 \*\*Windows 설치 프로그램 (Installer)\*\*을 제공할 수도 있습니다. 설치 프로그램은 Start Menu 등록, 바탕화면 아이콘, 폴더 연결(우클릭 메뉴 “이 폴더를 애니메이션 정리하기” 같은) 등을 포함할 수 있습니다. 하지만 처음에는 포터블 실행 파일만 제공하고, 피드백에 따라 인스톨러를 마련합니다.

* **업데이트 배포**: 정기적인 업데이트를 위해 **자동 업데이트 기능**을 고려합니다. 앱 자체에 업데이트 체크 기능을 넣어, GitHub Releases나 서버에 버전 정보를 조회하고 새 버전이 있으면 사용자에게 알려 다운로드/적용하게 할 수 있습니다. `pip`로 배포하지 않는 독립 실행 앱이므로, 이 기능은 고객 만족도에 영향을 줍니다. 구현은 어렵지 않으나, 초기 버전에서는 수동 업데이트로 안내하고, 사용자가 중요 문제를 제기하면 패치 버전을 배포하는 방식으로 진행합니다.

* **로그와 오류 보고**: 배포 버전에서는 상세 로그를 남기되, 사용자에게는 가급적 노출하지 않습니다. 치명 오류 발생 시 (예외 처리되지 못한 에러 등) 프로그램이 죽지 않고 오류 상황을 알려주며, **오류 리포트**를 생성하여 개발자에게 보낼 수 있도록 합니다. 예를 들어 오류 내용을 텍스트로 저장해두고, 사용자가 “오류 보고” 버튼을 누르면 GitHub 이슈 페이지나 이메일로 보낼 수 있게 하는 겁니다. 이를 통해 현장에서 발견되는 버그를 신속히 수집합니다.

* **성능 모니터링**: 배포 후 사용자들의 라이브러리 규모에 따라 성능 이슈가 표면화될 수 있습니다. 이를 위해 옵션으로 **디버그 모드**를 제공하여, 작업 단위 시간 측정 로그를 남기게 할 수 있습니다. 큰 폴더에서 느리다는 피드백이 오면, 디버그 모드 실행을 안내하여 어디서 병목이 있는지 파악합니다. 필요하면 특정 연산(예: 해시 계산)에 C 구현 또는 JIT 최적화(PyPy 등)를 적용하는 식으로 튜닝합니다.

* **기능 추가와 플러그인 업데이트**: 새로운 애니메이션 DB 서비스가 나오거나, 기존 API의 변경이 있을 때 (예: AniDB API 스펙 변경, MAL 사이트 개편) 대응이 필요합니다. 플러그인 구조 덕분에 해당 부분만 수정하여 업데이트 버전을 내면 되지만, API 변경에 프로그램이 갑자기 일부 기능이 멈출 수 있다는 점을 사용자에게 공지하고, 빠르게 업데이트를 제공하는 것이 중요합니다. GitHub 리포지토리를 운영하여 이슈 트래킹 및 사용자 요청 기능을 수렴하고, 오픈소스로 공개하여 외부 기여를 받을 수도 있습니다.

* **사용자 가이드와 문서**: 배포 시 **간단한 사용 설명서**를 함께 제공합니다. 예를 들어 README.md 또는 PDF 매뉴얼로 설치 방법, 초기 설정 (API 키 입력 등), 기본 사용법(폴더 선택 -> 정리 버튼) 등을 도식과 함께 설명합니다. 또한 각 기능별 세부 옵션(예: 정리 규칙 커스터마이즈, 즐겨찾기, 통계 보는 법 등)도 문서화합니다. 이 문서는 한글로 제공하되, UI 용어와 기술명은 영어 병기하여 이해를 돕습니다.

* **라이선스와 감사**: 사용된 오픈소스 라이브러리들의 라이선스를 검토하여, 배포물에 license 파일을 포함합니다. 특히 PySide6 (LGPL), watchdog (Apache), requests (Apache) 등은 비교적 간단하지만, 만약 우리가 가져다 쓴 코드 조각이나 번들링한 프로그램이 있으면 그에 맞는 조치를 합니다. 상업적 활용이 아니더라도 오픈소스 의무를 지킵니다.

* **향후 계획**: 유지보수 측면에서, 앞으로 추가 구현하고자 하는 기능들(예: 모바일 연동, 웹 UI 추가, Cross-platform 지원 등)을 고려한 코드 구조 유연성을 유지합니다. 윈도우 전용으로 시작하지만, 논리코드와 인터페이스를 분리해두면 PySide6를 사용하여 macOS/Linux 빌드도 나중에 시도할 수 있습니다. 또는 Electron으로 전환하는 경우를 대비해 백엔드(API 통신, DB)는 모듈화 해두고, 프론트엔드는 갈아끼울 수 있도록 합니다.

마지막으로, 배포 후에도 사용자의 목소리를 지속적으로 듣고 개선을 이어나가는 것이 중요합니다. 이를 위해 사용자 커뮤니티 (예: 디스코드, 오픈 카카오톡, 깃허브 Discussions 등)를 운영하여 피드백 통로를 열어둡니다. 안정적인 배포와 적극적인 유지보수를 통해 본 애플리케이션이 애니메이션 감상자들에게 신뢰받는 툴이 되도록 노력하겠습니다.

---

以上が、要求された 사양に基づいて作成された Windows専用アニメ動画ファイル整理アプリケーションの詳細な開発計画書です (요약: 위는 요구사항에 따라 작성된 Windows 전용 애니메이션 파일 정리 애플리케이션의 상세 개발 계획서입니다). 각 모듈의 설계 의도와 구현 전략을 상세히 다루었으며, 참조한 자료【4†L496# Windows 전용 애니메이션 파일 정리 애플리케이션 개발 계획서

## 1. 목표

이 프로젝트의 목표는 **Windows 전용 독립 실행형 애니메이션 파일 정리 애플리케이션**을 개발하는 것입니다. 사용자가 로컬에 보유한 애니메이션 동영상 파일들의 폴더를 지정하면, 프로그램이 **외부 메타데이터 API** (예: AniDB, TMDB 등)를 활용하여 각 파일의 애니메이션 정보를 조회하고, **파일을 연도 → 분기 → 시리즈명 → 에피소드 형태의 디렉토리 구조로 자동 정리**해 줍니다. 이를 통해 사용자는 애니메이션 파일을 체계적으로 관리하고, 부가적인 정보(에피소드 제목, 방영일, 썸네일 등)도 함께 활용할 수 있게 됩니다.

## 2. 전체 시스템 구성

애플리케이션은 **GUI 클라이언트** 형태로 제공되며, 내부적으로 파일 식별/정리 로직, 메타데이터 수집 플러그인, 데이터베이스, 미디어 플레이어 연동 모듈로 구성됩니다. 아래 **전체 시스템 구성도**는 주요 구성 요소와 상호 작용을 나타냅니다.

&#x20;*Windows 전용 애니메이션 파일 정리 애플리케이션의 시스템 아키텍처 구성도.* 각 구성 요소는 다음과 같습니다. 사용자 인터페이스(GUI)를 통해 사용자가 폴더를 선택하거나 정리 옵션을 지정하면, **코어 로직**이 해당 경로의 파일을 스캔하여 해시를 계산하고 파일 정보를 추출합니다. 그 후 **메타데이터 플러그인 모듈**을 통해 AniDB, TMDB, MyAnimeList, AniList 등의 외부 API로부터 필요한 **메타데이터 조회 요청**을 보내고, 응답으로 **시리즈 및 에피소드 정보**를 받아옵니다. 가져온 메타데이터는 \*\*로컬 데이터베이스(SQLite)\*\*에 캐시되어 저장되며, 이후 파일을 사용자가 지정한 규칙에 따라 **폴더 생성 및 파일명 변경**을 수행하여 정리합니다. GUI에는 정리 결과(폴더 구조, 에피소드명 등)가 갱신되어 표시됩니다. 사용자가 특정 에피소드를 선택해 **재생**을 요청하면, 코어 로직이 \*\*외부 미디어 플레이어(VLC/MPV)\*\*를 호출하여 영상을 재생하고, 재생 완료 이벤트 등을 다시 코어로 받아와 **시청 기록**으로 DB에 저장합니다. 새로운 파일이 폴더에 추가되는 경우 \*\*파일 시스템 감시 모듈(Watchdog)\*\*이 변화를 감지하여 코어 로직에 통지함으로써, 사용자가 수동으로 명령하지 않아도 자동으로 정리 프로세스를 재실행할 수 있습니다.

## 3. 핵심 기술 스택 및 라이브러리

본 애플리케이션은 **Python**을 주 언어로 개발하는 것을 기본으로 합니다. Python은 풍부한 라이브러리와 생산성으로 인해 요구 기능을 구현하기에 적합하며, 또한 Windows 환경에서의 배포도 비교적 용이합니다. 성능 이슈나 GUI 구현상의 이유로 Python이 부적합하다고 판단될 경우 C# (WPF) 등의 대안을 고려할 수 있지만, 여기서는 Python 기반으로 계획합니다.

* **GUI 프레임워크**: Python 기반 GUI 중에서는 \*\*PySide6 (Qt for Python)\*\*를 사용하는 방향을 우선적으로 검토합니다. PySide6는 Qt6 프레임워크를 Python으로 사용할 수 있게 한 바인딩으로, 상용 소프트웨어에서도 활용될 정도로 **안정적이고 완성도 높은 GUI** 구현이 가능합니다. Qt의 풍부한 위젯과 테마 지원을 통해 현대적인 UI/UX를 구축할 수 있고, Windows뿐만 아니라 추후 Cross-platform 확장성도 확보할 수 있습니다. (대안: C# WPF의 경우 .NET 생태계의 장점이 있으나 Python에서 벗어나게 되고, Electron의 경우 웹 기술을 사용하여 개발할 수 있으나 메모리 사용 등의 부담이 있어 신중한 평가가 필요합니다.)

* **데이터베이스**: **SQLite**를 내장 DB로 사용합니다. SQLite는 별도 서버 없이 파일 기반으로 동작하는 **경량 DB 엔진**으로, Python에 내장된 `sqlite3` 모듈을 통해 바로 사용할 수 있습니다. SQLite는 단일 파일로 데이터를 보관하므로 설치나 설정이 간편하고, Windows 클라이언트 애플리케이션의 로컬 데이터 저장소로 이상적입니다. 추후 사용자 수 증가나 동시접속, 원격 접속 요구가 생길 경우를 대비해 **PostgreSQL** 등으로 마이그레이션할 수 있도록 ORM을 활용하여 추상화할 계획입니다.

* **ORM 및 데이터 액세스**: Python의 **SQLAlchemy**를 사용하여 SQLite DB를 액세스합니다. SQLAlchemy는 ORM(Object-Relational Mapping)을 제공하여 파이썬 객체로 DB를 다룰 수 있게 해주며, 특정 DBMS에 종속되지 않는 코드 작성을 도와줍니다. 이를 통해 SQLite로 개발하더라도, 설정만 바꾸면 PostgreSQL 등으로 이전이 비교적 용이하도록 합니다.

* **메타데이터 조회용 HTTP 클라이언트**: **Requests** 라이브러리를 사용합니다. Requests는 Python에서 HTTP 요청을 간편하게 처리할 수 있는 사실상의 표준 라이브러리로, REST API 호출에 적합합니다. 각종 외부 API (TMDB, AniDB HTTP, AniList GraphQL 등)를 호출하는 데에 활용합니다.

* **파일 시스템 모니터링**: **Watchdog** 라이브러리를 사용합니다. Watchdog은 파일시스템의 변경 사항(생성, 삭제, 수정, 이동 등)을 실시간으로 모니터링할 수 있는 Python 라이브러리로, 백그라운드 스레드로 폴더를 감시하여 새로운 동영상 파일이 추가되거나 이름이 바뀌는 등의 이벤트를 잡아낼 수 있습니다. 이를 이용해 사용자가 지정한 폴더에 변화가 생기면 자동 정리 기능을 트리거하여 **실시간 폴더 동기화**를 구현합니다.

* **해시 연산**: AniDB의 파일 식별에 요구되는 **ED2K 해시**를 계산하기 위해, Python 표준 라이브러리의 `hashlib` (MD4 알고리즘)과 추가 로직을 사용하거나, 오픈소스 구현을 활용합니다. ED2K 해시는 파일을 일정 크기 블록으로 나눈 후 MD4 해시를 여러 번 적용하여 구하는 특수한 해시로, AniDB에서 파일을 식별하는 데 사용됩니다. 멀티스레드로 대용량 파일의 해시를 계산하기 위해 Python의 `concurrent.futures`(ThreadPoolExecutor) 등을 활용하며, 필요 시 C로 작성된 해시 함수를 사용하는 라이브러리를 도입해 성능을 높입니다 (예: `pyed2k` 또는 `hashlib` + `pycryptodome`).

* **미디어 플레이어 연동**: 외부 플레이어인 **VLC** 또는 **MPV**와 연동합니다. 두 플레이어 모두 CLI 인터페이스나 Python 바인딩을 제공하므로, **python-vlc** 또는 **python-mpv** 패키지를 이용해 제어할 수 있습니다. 예를 들어 `python-mpv` 라이브러리는 ctypes를 통해 MPV 플레이어를 제어하여 재생, 일시정지 등을 프로그래밍적으로 다룰 수 있고, JSON IPC를 통해 외부 mpv 프로세스를 통제하는 방법도 있습니다. 이러한 방법을 통해 GUI에서 “재생” 버튼을 누르면 해당 플레이어를 임베드하거나 새 프로세스로 실행하고, 재생 상태를 피드백 받아오는 통합을 구현합니다.

* **기타**: 그 외에도 JSON 데이터 처리를 위한 `json` 모듈, 날짜 및 기간 계산을 위한 `datetime` 및 `pytz`, 로그 기록을 위한 `logging` 모듈 등을 사용합니다. GUI 쓰레딩과 백엔드 작업 분리를 위해 Python의 `threading`이나 PySide6의 `QThread`를 활용하여, 해시 계산이나 API 통신 중에도 UI가 응답성을 유지하도록 합니다.

## 4. 기능별 모듈 설계

요구사항에서 제시된 주요 기능들을 중심으로, 각 기능을 담당할 모듈과 설계 방안을 설명합니다. 모듈별로 책임과 흐름을 명확히 분리하여 유지보수성과 확장성을 높이는 것을 기본 원칙으로 합니다.

### 4.1 파일 해시 기반 에피소드 식별 (AniDB 기반)

**파일 식별 모듈**은 주어진 동영상 파일이 어떤 애니메이션 시리즈의 몇 화인지 식별하는 역할을 합니다. 이를 위해 **해시 기반 식별 알고리즘**을 구현합니다. 구체적으로, **AniDB**에서 사용되는 ED2K 해시를 활용합니다. AniDB는 각 동영상 파일을 ED2K 해시로 **고유 식별**하는 시스템을 갖추고 있으며, 이 해시 값과 파일 크기를 조합하여 AniDB 데이터베이스에서 해당 파일이 어떤 애니메이션의 어떤 에피소드인지 조회할 수 있습니다.

* **ED2K 해시 계산**: 파일을 9,728,000 바이트 청크로 분할하고 각 청크에 MD4 해시를 적용한 뒤, 그 해시들로 다시 MD4 해시를 하는 방식으로 ED2K 해시를 구합니다. 이 과정은 대용량 파일에서도 효율적으로 동작하도록 스트리밍 방식으로 구현하거나, 멀티코어를 활용하여 병렬 처리합니다. 예를 들어 오픈소스로 공개된 `anidbcli` 도구도 멀티코어 ED2K 해싱을 지원하고 있어 이러한 기법을 참고할 수 있습니다.

* **AniDB API 조회**: 해시와 파일 크기 정보를 갖고 AniDB에 조회를 보냅니다. AniDB는 공개 API로 **UDP API**를 제공하며, 파일 해시를 조회하면 해당 파일의 \*\*파일 정보(file info)\*\*를 반환합니다. 이 파일 정보에는 **에피소드 ID**와 **애니메이션 시리즈 ID** 등이 포함되어 있어서, 이를 통해 해당 파일이 어떤 시리즈의 몇 번째 에피소드인지를 알 수 있습니다. AniDB API는 사용 전에 **유저 계정 및 클라이언트 인증**이 필요하므로, 애플리케이션에서 AniDB 클라이언트로 등록하고 사용자에게 AniDB 계정 정보를 받는 과정을 거칠 것입니다. (AniDB는 API 사용량에 엄격한 제한이 있어, 한 계정/IP당 일정량 이상의 요청을 보내면 **BAN** 당할 수 있으므로 주의가 필요합니다. 실제로 AniDB는 하루 250여 개 이상의 파일을 처리하는 경우 차단될 수 있으며, **중복 요청을 피하기 위한 로컬 캐싱**을 강하게 권고하고 있습니다.)

* **파일명 기반 보조 식별** (선택사항): 해시 기반 식별이 실패하거나 AniDB에 없는 파일의 경우, **파일명 파싱**을 통한 보조 식별 로직도 준비합니다. 예를 들어 파일명이 `[SubsPlease] Attack on Titan - 01 [1080p].mkv`와 같은 패턴이라면 정규표현식 등을 통해 시리즈명(`Attack on Titan`)과 에피소드 번호(`01`)를 추출하고, TMDB나 AniList 등의 검색 API를 통해 해당 시리즈를 찾는 방법입니다. 이는 해시 기반 방법보다 신뢰도는 낮지만, 백업 수단으로 유용할 수 있습니다.

* **결과 처리**: AniDB로부터 에피소드 정보(시리즈 ID, 에피소드 ID 등)를 받아오면, 이를 다른 메타데이터 API와 연계하기 위한 키로 활용합니다. 시리즈 ID는 가급적 **공용 식별자**로 변환하거나, 시리즈명을 받아와서 TMDB/MAL 등의 API 호출에 활용합니다. (일부 데이터베이스 간에는 상호 ID 매핑이 존재하기도 합니다. 예를 들어 AniDB와 TheTVDB 간 매핑 파일, AniList와 MAL ID 연계 등이 알려져 있습니다. 필요한 경우 이러한 매핑 데이터를 활용할 것입니다.)

### 4.2 메타데이터 수집 (다양한 API 플러그인 연동)

파일이 어떤 에피소드인지는 AniDB 해시로 확인했다면, **그 이상**의 부가 정보를 얻기 위해 다양한 외부 **메타데이터 API**를 활용합니다. **메타데이터 모듈**은 플러그인 구조로 설계되어, **TMDB**, **AniDB**, **MyAnimeList**, **AniList** 등 여러 출처로부터 정보를 수집하고 통합합니다. 각 API 별로 각각의 플러그인 클래스를 두어 구현하고, 공통된 인터페이스를 통해 필요한 정보를 요청할 수 있게 합니다.

* **AniDB 플러그인**: 파일 식별 단계에서 AniDB로부터 얻은 시리즈 ID, 에피소드 ID 등을 이용하여 **AniDB의 추가 정보**를 가져옵니다. AniDB 자체도 애니메이션의 기본 정보(예: 일본어 제목, 영문 제목, 에피소드 제목 목록, 방영 연도, 화수 등)를 제공하므로, 우선적으로 AniDB를 조회합니다. AniDB UDP API 또는 HTTP API를 사용하며, 파일 식별과 동일한 인증이 필요합니다. AniDB에서 얻은 기본 정보는 신뢰도가 높으며, 특별히 애니메이션에 특화된 데이터(에피소드별 상세 제목, 파일 CRC 등)도 받을 수 있습니다. 다만 AniDB API는 앞서 언급했듯이 호출 제한이 엄격하므로, **필요한 경우에만 조회**하고 결과는 최대한 캐싱합니다.

* **TMDB (The Movie Database) 플러그인**: TMDB는 영화/TV시리즈 DB이지만 유명 애니메이션의 정보도 많이 포함되어 있어, 애니메이션 시리즈의 개요, 포스터 이미지, 제작사, 방영일 등 **풍부한 정보를 REST API로 제공**합니다. TMDB API는 키를 발급받아야 하지만 비교적 사용이 자유로우며, 클라이언트 인증만으로 이용 가능합니다. TMDB 플러그인은 **시리즈명**이나 **AniDB에서 얻은 연도 정보** 등을 사용하여 TMDB의 Search API로 해당 애니메이션을 검색하고, 일치하는 TV 시리즈 ID를 가져온 뒤, **에피소드 목록과 줄거리, 포스터 이미지 URL** 등을 받아옵니다. 이렇게 수집한 정보는 AniDB에서 제공하지 않는 **줄거리 요약, 시리즈 설명, 출연 성우 정보** 등의 부가 데이터로 활용됩니다.

* **MyAnimeList(MAL) 플러그인**: MyAnimeList는 큰 애니메이션 커뮤니티 DB로, 평점, 랭킹, 리뷰 등의 정보가 강점입니다. 그러나 MAL의 공식 API는 OAuth 인증이 필요하고 제약이 많으므로, 본 애플리케이션에서는 **비공식 공개 API인 Jikan**을 사용합니다. Jikan은 MAL 웹사이트를 **크롤링하여 API 형태로 제공하는 서비스**로, MAL에서 공식으로 제공하지 않는 많은 정보를 얻을 수 있습니다. MAL 플러그인은 Jikan의 REST 엔드포인트를 통해 시리즈 검색, 상세 정보, 사용자 평점 등을 가져옵니다. 예를 들어 “원피스”라는 시리즈명을 검색하여 MAL ID를 얻고, 해당 ID로 상세 정보(평점, 장르, 개요 등)를 가져오는 흐름입니다. Jikan은 공개 API이지만 과도한 호출 시 자체 rate limit(분당 60회 등)이 있으므로 적절한 캐싱이 필요합니다.

* **AniList 플러그인**: AniList는 AniDB/MAL과 유사한 애니메이션 DB로서 **GraphQL 기반 API**를 제공합니다. AniList API는 비상업용으로 무료 사용이 가능하며 분당 90회의 쿼리 한도를 가집니다. AniList 플러그인은 Python의 `gql` 라이브러리 등을 활용하여 GraphQL 쿼리를 보내고, 시리즈 및 에피소드 정보를 받아올 것입니다. AniList의 강점은 **유저 선호도 기반 추천, 태그 및 트렌드 정보**인데, 본 프로젝트에서는 주로 시리즈의 **평균 평점, 인기 지표, 태그** 등을 수집하여 활용할 수 있습니다. (예: 태그를 이용해 유사 작품 추천에 활용 가능.)

* **통합 및 충돌 처리**: 서로 다른 출처에서 얻은 메타데이터를 통합할 때 충돌이나 불일치가 발생할 수 있습니다. 예를 들어 AniDB와 TMDB에서 제공하는 에피소드 수나 방영일이 다를 경우 우선순위를 정해야 합니다. 기본적으로 **식별 정보는 AniDB 기준**을 따르고, **사용자에게 표시하는 줄거리나 포스터 등은 TMDB/MAL 등에서 보완**하도록 합니다. 동일한 필드에 대해 여러 소스가 있을 경우 신뢰도나 최신 업데이트 빈도를 고려해 우선순위를 결정합니다. 사용자가 설정에서 특정 소스를 신뢰하도록 우선순위를 커스터마이징할 수도 있게 합니다. 또한 가능한 경우 **여러 출처의 데이터를 모두 표시**하는 것도 방법입니다 (예: AniDB 평균평점 vs MAL 평점 비교 등).

* **플러그인 추가 확장성**: 설계를 플러그인 아키텍처로 함으로써, 향후 **다른 API 연동을 추가**하기 쉽습니다. 예를 들어 **Kitsu** API나 **AnimeNewsNetwork** API 등을 추후 플러그인으로 추가 구현해도 코어 로직을 수정하지 않고 연결할 수 있습니다. 이때 새로운 플러그인은 표준 인터페이스만 구현하고 설정 파일에 등록하면 애플리케이션에 통합됩니다 (플러그인 구조에 대한 자세한 내용은 아래 7장에서 설명합니다).

이러한 멀티-소스 메타데이터 수집을 통해, 프로그램은 **상세하고 풍부한 애니메이션 정보**를 사용자에게 제공합니다. 예를 들어 Shoko라는 오픈소스 애니메이션 관리 프로그램도 AniDB 해시 매칭으로 식별한 후 다른 출처의 메타데이터를 함께 채워 넣는 방식을 취하고 있는데, Shoko는 “파일 해시를 AniDB와 대조하여 정확한 에피소드 식별을 한 다음, 다른 소스에서 메타데이터를 끌어온다”고 소개하고 있습니다. 본 애플리케이션도 동일한 전략을 따라, **정확한 식별 + 풍부한 정보**를 동시에 달성하고자 합니다.

### 4.3 사용자 설정에 따른 파일 정리 (폴더 이동 및 리네이밍)

**파일 정리 모듈**은 식별된 애니메이션 파일들을 사용자 정의 규칙에 맞게 폴더로 이동시키고 파일명을 변경하여 정돈하는 기능을 담당합니다. 기본 정리 규칙은 **“연도/분기/시리즈명/에피소드 번호 – 에피소드 제목”** 형식으로 폴더를 구성하는 것입니다. 예를 들어 “진격의 거인 1화” 영상 파일이 2013년 4월(2분기)에 방영되었다면, 정리 결과로 `2013\2분기\진격의 거인\진격의 거인 - 01화.mkv` 와 같이 배치됩니다. (분기는 1분기=겨울(1~~3월), 2분기=봄(4~~6월), 3분기=여름(7~~9월), 4분기=가을(10~~12월)로 구분하여 사용합니다.)

* **폴더 생성 규칙**: 정리 모듈은 우선 대상 파일의 메타데이터에서 **방영 연도**와 **방영 분기**를 확인합니다. 이 정보는 AniDB나 TMDB에서 얻은 첫 방송일을 기준으로 산출합니다. 해당 폴더 (`연도\분기`)가 없으면 새로 만들고, 그 안에 **시리즈명 폴더**를 생성합니다. 시리즈명은 기본적으로 **국내 방영명**이나 **원제** 중 사용자 설정에 따라 선택할 수 있게 합니다 (예: 국내명 없는 경우 원어명 사용 등).

* **파일명 규칙**: 에피소드 번호 및 제목을 이용하여 파일명을 구성합니다. 에피소드 번호는 두 자리 또는 세 자리 숫자로 포맷하고, 에피소드 제목은 가능하면 짧게 (또는 사용자 옵션으로 포함 여부 결정). 예: "`시리즈명 - 01화.mp4`" 또는 "`시리즈명 - S1E01.mp4`" 등. 사용자가 **파일명 패턴을 커스터마이즈**할 수 있도록, 템플릿 문자열을 설정에 두어 `%series%`, `%ep_no%`, `%title%` 등의 플레이스홀더를 지원합니다. (Shoko 등 기존 도구들도 사용자 정의 리네이밍 패턴을 제공하며, 이러한 기능은 파일 정리의 유연성을 높입니다.)

* **관련 파일 처리**: 영상 파일 이외에 같은 이름을 가진 자막 파일(.srt) 등이 있다면, 이동/이름변경 시 함께 처리합니다. 예를 들어 `Attack.on.Titan.S01E01.ass` 자막이 있으면 영상과 동일한 폴더로 옮기고 시리즈명에 맞춰 이름을 변경합니다. 이는 `*.ass`, `*.srt`, `*.sub` 등 **자막/부가 파일 패턴을 사전에 정의**하여 구현하며, 변경 전/후의 매핑을 잘 유지해야 데이터 손실이 없습니다. (Anidbcli 역시 “동일한 이름의 자막 및 기타 파일도 함께 이동/변경” 기능을 제공하는데, 본 애플리케이션도 유사하게 구현합니다.)

* **이름 충돌 및 중복 처리**: 동일한 에피소드 파일이 두 개 이상 있거나(예: 다른 릴 그룹의 중복 에피소드) 이미 해당 경로에 같은 이름의 파일이 존재하는 경우 처리 방법을 정합니다. 일반적으로 중복 에피소드에 대해서는 품질이 더 좋은 파일을 우선 남기고 다른 파일은 별도 폴더(`Duplicates` 등)에 모으는 기능도 고려합니다. 파일 이름 충돌 시에는 `[1]`과 같은 식으로 번호를 붙이거나, 사용자에게 알림을 주어 수동 선택하게 할 수 있습니다.

* **원본 보존 옵션**: 파일 이동 작업은 **위험(파일 손상이나 분실) 방지**를 위해 신중해야 합니다. 기본값으로 **원본 폴더에 대한 백업 옵션**을 제공하여, 이동 작업 이후 일정 기간 원본 위치에 파일을 복사해 두거나, 휴지통으로 보내는 식으로 **실수 복구**를 대비합니다. 또한 정리 작업을 **시뮬레이션 모드**로 실행하여, 실제로 파일을 옮기기 전에 어떻게 구조가 바뀔지 미리 보고 사용자가 확인하도록 하는 기능도 계획합니다.

* **사용자 인터페이스 연동**: GUI에서는 정리 작업의 진행 상황(몇 개 처리되었는지, 현재 이동중인 파일)은 진행바 형태로 보여주고, 완료 후 결과 폴더를 탐색기에서 열어볼 수 있는 버튼을 제공합니다. 특정 시리즈를 선택해서 그 시리즈만 정리하거나, 개별 파일에 대해서 수동으로 경로를 지정할 수 있는 고급 기능도 고려합니다.

이 모듈의 목표는 **사용자 개입 최소화**로 최대한 깔끔한 라이브러리 폴더를 구축하는 것입니다. 결과적으로 사용자는 정돈된 계층 구조 안에서 원하는 애니메이션을 쉽게 찾고 관리할 수 있게 됩니다.

### 4.4 메타데이터 캐싱 및 오프라인 사용 지원

메타데이터 캐싱은 두 가지 목적이 있습니다: **(1) 성능 향상 및 API 호출 제한 대응**, **(2) 오프라인 환경 지원**. 이를 위해 **캐시/DB 모듈**이 존재하며, 앞서 언급한 SQLite DB를 활용합니다.

* **API 응답 캐싱**: 외부 API로부터 불러온 시리즈 정보, 에피소드 정보 등을 로컬 DB에 저장합니다. 기본 키로는 해당 리소스의 고유 ID(AniDB ID, TMDB ID 등)를 사용하고, 응답 JSON 전체 혹은 필요한 필드만 저장합니다. 예를 들어 **AniDB의 시리즈 ID 1234**에 대한 **시리즈 제목/에피소드 목록** 데이터를 DB에 저장해 두었다면, 다음번에 같은 ID를 조회할 때는 API를 부르지 않고 DB에서 불러올 수 있습니다. 이는 AniDB API 정책상 **반복 데이터 요청 시 밴(Ban)** 위험을 피하는 데 필수적입니다. 캐시된 데이터에는 타임스탬프를 두어, 일정 기간(예: 24시간 또는 7일 등) 경과 후에는 자동으로 새로 고침할 수 있도록 합니다. (특히 방영중인 최신 애니메이션의 경우 계속 에피소드가 추가되므로 주기적으로 업데이트 필요.)

* **로컬 DB 구조**: 데이터베이스에는 **Series(애니메이션 작품)** 테이블, **Episode(에피소드)** 테이블, **File(파일)** 테이블 등이 있고, 각 테이블에 메타데이터 관련 필드를 둡니다. 아래는 **DB 스키마의 예시**입니다.

```plaintext
Series table:
- series_id (INT, PK) – 시리즈 내부 식별자
- title (TEXT) – 기본 시리즈명
- title_jp (TEXT) – 일본어 원제
- year (INT) – 첫 방영 연도
- season (TEXT) – 첫 방영 분기 ("1분기", "2분기", ...)
- anidb_id (INT) – AniDB에서의 작품 ID (있을 경우)
- mal_id (INT) – MyAnimeList 작품 ID (있을 경우)
- tmdb_id (INT) – TMDB 시리즈 ID (있을 경우)
- ... (장르, 감독 등 추가 메타데이터)

Episode table:
- episode_id (INT, PK) – 에피소드 내부 식별자
- series_id (INT, FK to Series) – 소속 시리즈
- episode_number (INT) – 작품 내 에피소드 번호
- title (TEXT) – 에피소드 제목
- anidb_ep_id (INT) – AniDB 에피소드 ID (있을 경우)
- airdate (DATE) – 해당 화 방영일
- ... (에피소드 개별 줄거리 등 추가 메타데이터)

File table:
- file_id (INT, PK) – 파일 내부 식별자
- episode_id (INT, FK to Episode) – 대응하는 에피소드
- file_path (TEXT) – 로컬 파일 경로
- ed2k_hash (TEXT) – 파일 ED2K 해시 값
- file_size (INT) – 파일 크기 (바이트)
- resolution (TEXT) – 해상도 (예: 1080p 등)
- codec (TEXT) – 비디오 코덱 (예: H.264 등)
- ... (오디오 트랙 정보 등 옵션)

WatchHistory table:
- history_id (INT, PK) – 시청 기록 ID
- file_id (INT, FK to File) – 시청한 파일
- watched_at (DATETIME) – 시청 완료 시간
- duration (INT) – 시청 소요 시간(초) 또는 진도율
- completed (BOOL) – 끝까지 시청했는지 여부

FavoriteSeries table:
- fav_id (INT, PK)
- series_id (INT, FK to Series) – 즐겨찾기 등록한 시리즈
- note (TEXT) – (옵션) 메모
```

위 스키마는 예시이며, 실제 구현 시에는 ORM 모델로 정의될 것입니다. 캐싱 관련해서 중요한 점은, **외부 API별 데이터**도 저장하는 것입니다. 예를 들어 MAL 평점이나 AniList 인기 순위 등이 시리즈별로 있을 경우, Series 테이블에 컬럼을 추가하거나 별도 테이블로 저장해둘 수 있습니다. 캐시된 데이터에는 마지막 업데이트 시각을 기록하여, 일정 시간이 지나면 자동으로 갱신하거나 사용자가 “새로 고침”할 수 있게 합니다.

* **오프라인 사용**: 일단 한 번 메타데이터가 캐싱되고 나면, 인터넷 연결이 없는 오프라인 상황에서도 최근에 정리한 라이브러리 정보는 계속 표시되고 활용될 수 있어야 합니다. 사용자는 **오프라인 상태**에서도 라이브러리의 목록을 보고, 검색하고, 재생(mark as watched)하는 등 기본 기능을 사용할 수 있습니다. 다만 새로운 폴더 정리나 메타데이터 갱신은 온라인일 때까지 보류하거나, 나중에 일괄 수행하도록 큐에 넣어둘 수 있습니다. (예: 사용자가 오프라인 상태에서 폴더를 지정하면 파일 해시 식별까지만 해두고, 메타데이터는 “나중에 가져오기”로 표시해두는 방식.)

* **메타데이터 업데이트**: 애니메이션의 정보는 시간이 지나면서 바뀔 수 있습니다 (예: 미방영 에피소드 제목이 나중에 채워짐, 또는 잘못된 정보 수정). 정기적으로 혹은 사용자가 원하는 시점에 “메타데이터 갱신” 기능을 통해 모든 시리즈의 최신 정보를 다시 가져와 업데이트할 수 있게 합니다. 이때도 이미 캐시된 데이터와 비교하여 변경된 부분만 갱신하는 방식으로 API 부하를 최소화합니다.

캐싱 전략을 적절히 운용함으로써, AniDB와 같은 서비스의 요청 제한에 걸리지 않으면서 쾌적한 사용자 경험(빠른 응답, 오프라인 사용)을 제공할 수 있습니다. 또한 초기 대량 라이브러리 정리 시 AniDB 요청이 몰리지 않도록, 한 번 조회한 시리즈는 파일 개수만큼 중복 조회하지 않고 한 번만 조회하도록 설계합니다.

### 4.5 미디어 플레이어 연동 (VLC 또는 MPV 통해 재생)

애플리케이션에서 **재생 버튼**을 누르면 지정된 외부 **미디어 플레이어**로 해당 파일을 열어주는 기능을 구현합니다. 또한 가능하면 **재생 상태 정보를 받아와 시청 기록으로 활용**합니다. 이를 담당하는 **플레이어 연동 모듈**의 설계는 다음과 같습니다.

* **외부 플레이어 선택**: 사용자 설정에서 기본 플레이어를 **VLC**나 **MPV** 중 선택할 수 있도록 합니다. (그 외 플레이어도 명령줄 인자가 지원되면 추가 가능하나, VLC와 MPV는 오픈소스이며 제어 API가 잘 갖춰져 있으므로 우선 이 둘을 고려합니다.) 기본값으로 VLC를 사용하도록 하고, 사용자가 시스템에 해당 플레이어를 설치해 두어야 합니다. 설치 경로를 자동 감지하거나 사용자가 지정할 수 있게 합니다.

* **플레이어 실행 방식**: 두 가지 접근을 검토합니다. **(A) 외부 실행:** 단순히 OS 명령으로 VLC 또는 MPV를 실행하면서 파일 경로를 전달하는 방식. 이 경우 구현이 간단하고 호환성이 높지만, 재생 제어나 상태 피드백을 받기가 어렵습니다. **(B) 임베디드/IPC 제어:** PySide6 GUI 창 내부에 플레이어를 임베드하거나, 파이썬 바인딩으로 제어하는 방식. VLC의 경우 `vlc.py` 바인딩을 통해 파이썬 코드에서 VLC player 객체를 생성하고 영상 출력은 별도 창으로 띄울 수 있습니다. MPV의 경우 `python-mpv` 라이브러리를 통해 Qt 위젯 위에 표시하거나, IPC로 통신하면서 숨김 모드로 실행해 제어할 수도 있습니다. 여기서는 구현 난이도를 고려해 **외부 실행 + IPC 제어 혼합** 방안을 사용합니다: 플레이어는 독립 창으로 띄우되, IPC(예: MPV의 `--input-ipc-server` 옵션이나 VLC의 RC (remote control) 인터페이스)로 해당 프로세스와 통신하여 상태를 읽습니다.

* **재생 상태 모니터링**: MPV의 IPC나 VLC의 RC를 통해 **현재 재생 시간, 일시정지/재생 이벤트, 종료 이벤트** 등을 파악할 수 있습니다. 이를 통해 사용자가 에피소드를 끝까지 시청했는지, 중간에 중단했는지 등을 알아낼 수 있습니다. 예를 들어 MPV IPC로 `{ "event": "end-file" }` 이벤트가 오면 해당 파일 재생이 끝났음을 알 수 있습니다. 또는, GUI에서 아예 재생 완료는 체크하지 않고 사용자가 수동으로 "봤음 표시" 버튼을 눌러 시청 완료로 기록하게 할 수도 있습니다. 구현 복잡도를 고려해 초기 버전에서는 **수동 시청 완료 체크**로 두되, 향후 업데이트에서 자동 감지를 추가하는 방향으로 계획합니다.

* **시청 기록 저장**: 재생이 완료되면 **WatchHistory 테이블**에 해당 기록을 추가합니다. 기록에는 에피소드, 시각, 소요시간 등이 포함됩니다. 동시에 Series나 Episode 테이블에 별도의 `watched_flag`나 `last_watched` 필드를 두어, 최근 시청 여부를 빠르게 확인할 수 있게 할 것입니다. GUI에서는 이미 본 에피소드는 아이콘이나 색상으로 표시해서 한눈에 파악할 수 있도록 UX를 제공합니다.

* **플레이어 추가 기능 활용**: VLC와 MPV 모두 자막 자동로딩, 재생 위치 기억, 영상 품질 조정 등의 기능이 있습니다. 이러한 기능들은 대부분 플레이어 자체가 수행하지만, 애플리케이션 차원에서도 지원하면 좋은 것들이 있습니다. 예를 들어 “다음 화 자동 재생” 옵션을 두어 한 화 끝나면 다음 화를 자동으로 여는 기능, 전체 화면/자막 언어 등의 선호 설정을 플레이어 실행 옵션으로 넘기는 것 등이 가능합니다. 이러한 세부 기능은 사용자 편의를 높이는 요소로 고려합니다.

Shoko와 같은 유사 프로그램에서도 VLC/MPV, Kodi 등 여러 플레이어와 연동하여 **어디서든지 시청(Watch Anywhere)** 기능을 강조하고 있는데, 본 애플리케이션도 원클릭으로 재생이 이루어지고 시청 상태까지 관리되는 일원화된 환경을 제공하는 것을 목표로 합니다.

### 4.6 시청 기록 저장 및 통계/분석 기능

**시청 기록 및 통계 모듈**은 사용자의 콘텐츠 소비 패턴을 저장하고 분석하여 유용한 정보를 제공하는 역할을 합니다. 앞서 설명한 대로 각 에피소드의 재생 완료 시점을 **WatchHistory**에 기록하게 되며, 이를 토대로 다양한 통계와 편의 기능을 구현합니다.

* **시청 진행도 표시**: 사용자가 어느 시리즈를 어디까지 보았는지 추적하여 UI에 표시합니다. 예를 들어 특정 시리즈의 경우 “10/24 화 시청 (42%)”처럼 진행도를 보여주고, 마지막으로 본 에피소드 정보를 표시하여 이어보기가 쉽도록 합니다. 에피소드 리스트 뷰에서는 본 화는 체크 표시나 흐린 색으로, 안 본 화는 뚜렷하게 표시하는 등 UI 피드백을 줍니다.

* **간단한 시청 통계**: 데이터베이스의 WatchHistory를 이용해 **통계 정보를 대시보드 형태**로 제공합니다. 예를 들어:

  * 총 시청 에피소드 수, 총 시청 시간 (시간/분 단위 환산)
  * 일별/월별 시청 패턴 (예: 이번 달에 몇 화를 봤는지, 요일별 평균 시청 시간 등)
  * 가장 많이 본 장르, 가장 선호하는 시리즈 (시청 완료한 작품 수, 즐겨찾기 수 등)
    이러한 통계는 차트나 숫자 지표로 시각화하여 사용자에게 재미와 인사이트를 줍니다. 물론 초기 버전에서는 단순 합계 정도로 시작하고, 점차 기능을 늘려갑니다.

* **시청 기록 편집 및 동기화**: 잘못 기록된 시청 내역을 사용자가 수정하거나 삭제할 수 있는 기능을 둡니다. 또한 여러 PC에서 사용한다면 시청 기록을 **내보내기/가져오기**하거나, AniList/MAL 같은 사이트와 **동기화**하는 것도 고려합니다. (예: AniList API를 통해 특정 유저의 현재까지 본 에피소드 목록을 동기화하여 처음 세팅 시 가져오거나, 반대로 우리 앱의 기록을 AniList에 업데이트하는 등. AniList는 사용자별 **시청 상태 동기화 API**를 제공하므로 충분히 가능한 시나리오입니다.)

* **완주 작품 및 즐겨찾기**: 모든 에피소드를 다 본 시리즈는 **완주**로 표시하고, 사용자에게 “축하 메세지”를 주거나 **별도 목록**에 보여주는 등의 재미 요소를 넣을 수 있습니다. 즐겨찾기에 등록한 시리즈의 새 에피소드를 아직 안 봤으면 알려주는 등의 기능도 시청 기록과 연계하여 구현 가능합니다.

* **데이터 분석 확장**: 추후 머신러닝 등을 접목하여 사용자의 시청 기록을 기반으로 **선호 장르 분석**이나 **시청 패턴 분석**을 고도화할 수 있습니다. 예를 들어 늦은 밤에 시청을 많이 한다든가, 특정 스튜디오 작품을 많이 본다든가 하는 것을 자동으로 발견해낼 수 있습니다. 이러한 분석은 추천 시스템과도 연결될 수 있습니다.

### 4.7 즐겨찾기 시리즈 등록 및 추천 시스템 연동

**즐겨찾기(Favorites) 및 추천(Recommendation) 모듈**은 사용자가 특별히 좋아하는 작품을 관리하고, 새로운 작품을 제안해주는 기능을 다룹니다.

* **즐겨찾기 등록**: 사용자 인터페이스에서 어떤 시리즈에 “별표” 아이콘을 누르면 해당 시리즈를 즐겨찾기에 추가합니다. DB의 FavoriteSeries 테이블에 기록되며, 즐겨찾기 목록을 별도로 볼 수 있게 UI에 제공합니다. 즐겨찾기한 시리즈는 검색이나 목록에서 우선 노출하거나, 별도의 **즐겨찾기 섹션**에서 모아볼 수 있습니다. 또한 즐겨찾기 작품에 한해 업데이트 소식을 표시할 수도 있습니다 (예: 아직 방영중인 작품의 새 에피소드 방영일 알림).

* **추천 시스템 연동**: 추천은 내부 알고리즘 또는 외부 API를 통해 구현합니다.

  * **외부 API 활용**: AniList나 MAL 등 일부 서비스는 비공식적으로 “비슷한 작품” 정보를 제공하거나, 유저 기반의 추천 데이터를 가지고 있습니다. 예컨대 AniList GraphQL로 특정 작품의 **유사 태그를 가진 작품**을 질의하거나, MAL에서 **유저 추천(Recommendations)** 페이지를 스크레이핑하는 방법이 있습니다. 또는 **Anime Recommender API**와 같은 공개 API를 활용해 즐겨찾기 작품을 입력하면 비슷한 작품 리스트를 받을 수도 있습니다.
  * **내부 알고리즘**: 간단한 방식으로는, 즐겨찾기한 작품들과 **장르 혹은 태그가 겹치는 다른 인기 작품**을 찾아 추천할 수 있습니다. 우리 DB에 이미 여러 작품의 장르/태그 정보가 수집되어 있으므로, 이를 교집합 분석하거나, AniDB/TMDB 등의 유사 작품 목록을 활용하는 것입니다. 또 하나는 **협업 필터링(collaborative filtering)** 개념을 도입하는 것인데, 이는 많은 사용자 데이터가 있어야 하므로 초기엔 어렵지만, 만약 장기적으로 사용자 커뮤니티 기능이 생긴다면 적용을 고려할 수 있습니다.

* **추천 UI**: 추천된 작품 리스트를 애플리케이션 내에서 보여줄 때, 각 추천이 왜 선정되었는지에 대한 설명(예: “장르가 비슷함”, “당신의 즐겨찾기인 X와 동일 감독” 등)을 함께 표기하면 신뢰도를 높일 수 있습니다. 또한 마음에 들지 않는 추천은 제거하거나, 관심 목록에 추가하는 등의 액션을 제공하여, 사용자의 피드백을 추천 시스템에 반영하도록 합니다 (ex. 추천 결과에서 제외 목록 관리).

* **개인화 설정**: 사용자가 추천 시스템을 원하지 않으면 끌 수 있도록 하며, 추천에 사용할 즐겨찾기 기준도 사용자가 선택하게 합니다. 혹은 특정 즐겨찾기 작품을 기준으로 “이 작품을 좋아한다면...” 식의 추천을 볼 수 있게 UI를 구성할 수도 있습니다.

전반적으로 즐겨찾기/추천 기능은 부가 기능이지만, 애니메이션 감상 경험을 풍부하게 해 줄 수 있는 요소입니다. 특히 많은 작품을 관리하다 보면 새로운 작품을 찾는 것도 중요해지므로, 본 애플리케이션이 **사용자의 애니메이션 큐레이션 도우미**가 될 수 있도록 점진적으로 발전시켜 나갑니다.

## 5. 주요 외부 API 연동 설계

이 섹션에서는 애플리케이션이 통신하게 될 주요 외부 API들(AniDB, TMDB, MAL, AniList 등)의 사용 방식과 요구 사항을 정리합니다. 각 API의 인증 요건과 활용 범위를 파악하여, 안정적인 연동을 도모합니다.

### 5.1 AniDB API

* **API 종류**: AniDB는 주로 **UDP 프로토콜 기반 API**를 제공합니다. XML/JSON HTTP API도 제한적으로 있지만 공식 문서는 UDP 사용을 중심으로 합니다. **AniDB UDP API**를 사용하기 위해서는 클라이언트 식별자(API Key)와 AniDB 사용자 계정 자격증명(유저명/패스워드)이 필요합니다. 이는 AniDB가 비인증형 키보다 사용자 단위로 쿼리를 관리하기 때문인데, 이러한 특성 때문에 FileBot 같은 툴에서도 기본 지원을 꺼리기도 했습니다.

* **인증 및 세션**: 애플리케이션 시작 시 AniDB UDP에 **LOGINS** 패킷을 보내 인증을 수행하고 세션을 받아옵니다. 이후 쿼리 전송 시 해당 세션을 사용하며, 일정 기간 사용 없으면 세션이 만료되므로 필요한 경우 재인증을 합니다. 인증 정보(특히 비밀번호)는 암호화하여 로컬에 저장하거나, 세션 토큰만 저장하고 평문 비밀번호는 저장하지 않도록 유의합니다.

* **요청 종류**: 애플리케이션에서 사용할 AniDB API 요청은 주로 **FILE** (해시로 파일 정보 조회), **ANIME** (애니메이션 ID로 애니 정보 조회), **EPISODE** (에피소드 ID로 에피소드 정보 조회) 등이 있습니다. 첫 단계는 파일 식별을 위한 FILE 요청이며, 응답으로 애니메이션 ID와 에피소드 번호 등을 얻으면, 다음으로 ANIME 요청을 보내 시리즈 정보를 얻습니다. AniDB의 응답 데이터에는 작품의 기본 제목들(메인, 카나, 영어 등), 에피소드 리스트(제목, 방영일), 총 에피소드 수, 카테고리(장르) 등이 포함됩니다. 이를 파싱하여 DB에 저장합니다.

* **Rate Limit 및 Ban 회피**: AniDB는 앞서 말한 대로 엄격한 anti-leech 정책이 있습니다. 구체적으로 “2초에 하나보다 더 빠르게 요청을 보내지 말 것”, “동일 데이터를 반복 요청하지 말 것” 등이 있습니다. 이를 위해 **로컬 캐싱**은 필수이며, 여러 파일이 동일 시리즈에 속해 있으면 한 번만 시리즈 정보를 받아서 공유합니다. 또한 다수 파일 해시 조회 시 요청을 **Queue**에 넣고, 내부적으로 2초 딜레이를 지켜가며 순차 처리합니다. 만약 일정 수 이상의 요청으로 IP Ban이 걸릴 경우를 대비해, 애플리케이션에 **대기 및 재시도 로직**을 추가합니다 (ex. Ban 징후 감지 시 사용자에게 알리고 30분 후 자동 재시도).

* **기술 구현**: Python에서는 UDP 소켓 프로그래밍으로 직접 구현할 수도 있고, 앞서 검색한 `pyanidb`나 `anidbcli`의 일부 코드를 참고하여 UDP 프로토콜을 처리할 수 있습니다. 패킷 조립과 파싱에 주의해야 하며, 특히 UTF-8 문자열 처리를 제대로 해야 일본어 등의 데이터가 깨지지 않습니다. UDP이므로 패킷 유실 가능성도 있어, 타임아웃 후 재요청 처리도 넣습니다.

* **기타 활용**: AniDB API로 **이미지**(예: 애니메이션 포스터나 스크린샷)는 제공되지 않으므로, 이미지 관련해서는 TMDB 등의 데이터를 사용하게 될 것입니다. AniDB로부터는 텍스트 기반 정보 위주로 활용하고, AniDB 고유의 **Mylist** 기능(사용자 소장 리스트 관리)은 본 애플리케이션에서는 사용하지 않습니다(클라이언트로 AniDB MyList에 추가하는 API도 있지만, 우리 앱은 로컬 관리 목적이므로 굳이 AniDB 계정에 소장 데이터를 보낼 필요는 없습니다).

### 5.2 TMDB API

* **API 개요**: TMDB (The Movie Database)는 영화 및 TV 시리즈에 대한 방대한 정보를 가진 공개 DB로, **RESTful HTTP API**를 제공합니다. API 사용을 위해 TMDB 사이트에서 발급받은 **API Key**가 필요하지만, OAuth 등의 추가 인증은 요구하지 않습니다. API Key는 우리 애플리케이션에 내장하거나(클라이언트에서 숨기기 어렵다면 사용자로부터 입력받게 할 수도 있습니다) 앱 설정에 저장해두고 모든 요청에 `api_key` 파라미터로 포함하여 사용합니다.

* **요청 시나리오**: TMDB에서 애니메이션 정보를 얻는 주요 방법은 두 가지입니다:

  1. **Search API**: 애니메이션 **시리즈명을 검색**하여 TMDB의 시리즈 ID를 얻습니다. (엔드포인트: `/search/tv?query={name}` 등)
  2. **TV Details API**: 시리즈 ID를 안다면 해당 시리즈의 상세 정보와 에피소드 정보를 조회합니다. (`/tv/{series_id}` 및 `/tv/{series_id}/season/{season_number}` 등)

  애니메이션은 TMDB에서 보통 TV Series로 취급되며, 시즌/에피소드 구조로 되어 있습니다. 일본 애니메이션의 경우 보통 Season 1로 전체를 묶거나, 여러 기수(쿨)를 시즌1,2,...로 구분하기도 합니다. 이 점을 감안하여, 검색 결과를 매칭할 때 연도나 부제 등을 함께 고려합니다 (예: “Naruto” 검색 시 “Naruto Shippuden”과 구분 필요).

* **수집 데이터**: TMDB로부터 가져올 데이터는 **포스터 및 배너 이미지 URL**, **개요(description)**, **장르 정보**, **에피소드 러닝타임**, **제작사 정보** 등이 있습니다. 또한 에피소드별로 **에피소드 제목, 줄거리, 방영일**을 가져올 수 있습니다. 이 데이터들은 AniDB에는 없거나 영어로만 있을 수 있는 정보이므로, UI 표시용으로 유용합니다. 이미지의 경우 URL만 저장하고 실제 다운로드는 사용자가 볼 때 로드하거나, 캐싱 전략에 따라 썸네일은 미리 받아둘 수도 있습니다.

* **언어 설정**: TMDB API는 `language` 파라미터를 지원하여, 현지화된 데이터(예: 한국어 제목/개요)가 있을 경우 받을 수 있습니다. 한국 사용자라면 `"language=ko-KR"`로 요청하여 한글 데이터가 있으면 받도록 하고, 없을 경우 대비해 기본 영어 데이터를 함께 저장합니다. 다만 애니메이션의 한글 개요는 완비되지 않은 경우가 많으므로, 이중 언어 처리를 고려합니다.

* **요청 제한**: TMDB API의 이용 제한은 비교적 관대한 편입니다. 일정 시간당 요청 횟수 제한이 있으나 (예: 40/request per 10 seconds 등), 캐싱과 병합 요청으로 충분히 회피 가능할 것입니다. 대량 데이터의 경우 한 번에 여러 페이지를 가져와야 하는데, 이럴 때 타임슬립을 걸어둡니다. TMDB 측 정책상 API Key는 클라이언트에 노출될 수 있으므로, 악용되지 않도록 주의만 하면 됩니다.

* **TMDB와 AniDB 데이터 연계**: 혹시 AniDB의 데이터에 TMDB ID 매핑이 있는 경우 바로 활용할 수 있지만, 일반적으로는 없으므로 시리즈명으로 검색하게 됩니다. 그러나 **Shoko 등 일부 시스템은 AniDB와 TVDB/TMDB 간 매핑**을 내장하기도 하는데, 우리도 향후 오픈소스 매핑 데이터를 확보하면 사용하여, 검색 오류를 줄이고 바로 ID를 얻을 수 있을 것입니다.

### 5.3 MyAnimeList (MAL) / Jikan API

* **API 종류**: MyAnimeList는 공식 API (v2)가 존재하지만, OAuth2 인증을 요하는 사용자 전용 API이고 공개 애니 데이터 접근에 제약이 있습니다. 따라서 본 프로젝트에서는 **Jikan API**를 사용합니다. Jikan은 **비공식 공개 REST API**로, MyAnimeList 웹사이트의 공개 데이터를 **스크레이핑하여 JSON 형태로 제공**합니다. 버전 4 기준으로 `https://api.jikan.moe/v4` 아래 다양한 엔드포인트를 제공합니다.

* **데이터 수집 내용**: MAL은 **유저 평점**, **순위(rank)**, **인기도(popularity)** 등의 커뮤니티 지표를 가지고 있고, **태그 기반 분류** (예: “isekai”, “vampire” 등 이용자 지정 태그)가 풍부합니다. 우선 각 시리즈의 \*\*평균 평점(score)\*\*과 **인기도 순위**를 가져와 Series 테이블에 저장합니다. 또한 **장르**와 **테마 태그** 목록도 MAL이 제공하므로, 이 데이터를 활용해 장르 필드를 채우거나 내부적으로 태그 기반 추천에 쓰겠습니다. 에피소드 상세 정보는 MAL에서는 유료회원에게만 제공하므로 시리즈 단위 정보 중심으로 사용합니다.

* **엔드포인트 사용 예**:

  * 작품 검색: `/anime?q={query}` (예: `/anime?q=Naruto` → 여러 결과 중 “Naruto Shippuden” 확인)
  * 작품 상세: `/anime/{mal_id}` (예: `/anime/20` → “Naruto Shippuden” 상세 JSON)
  * 작품 추천: `/anime/{mal_id}/recommendations` (이 작품을 본 유저들이 추천한 다른 작품 리스트)
  * 작품 리뷰, 에피소드, 캐릭터정보 등도 엔드포인트가 있지만 우선은 필요 없음.

* **Rate Limit**: Jikan은 공개 API지만 분당 60회, 초당 3회 등의 제한이 있습니다. 이는 AniDB만큼 엄격하지 않으나, 여전히 대량 호출 시에는 캐싱과 간격 조정이 필요합니다. 본 애플리케이션은 Jikan 데이터를 캐싱하므로 일반적인 사용에서는 제한에 걸릴 가능성이 낮습니다. 또한 Jikan 쪽에서 MyAnimeList 차원에서의 rate limit에 걸릴 수 있다고 언급하므로, 한번 가져온 데이터는 24시간 캐시하는 그들의 정책에 따르게 됩니다 (Jikan은 자체적으로 24시간 캐시를 운영하므로 연속 요청 시에도 같은 응답을 주게 됩니다).

* **주의사항**: Jikan은 스크레이핑 기반이라 MAL 사이트 구조 변화 시 동작이 불안정해질 수 있습니다. 이를 대비해 Jikan API가 실패할 경우 대비책(예: AniList로 대체 조회나, 캐시된 마지막 정보 사용)을 마련합니다. 또한 MAL ID를 AniDB나 AniList ID로부터 얻는 매핑은 없으므로, 시리즈명을 통해 검색해야 하고, 동명 이작품 구분을 위해 연도 등의 정보를 함께 고려해야 합니다. (예: “Fate/stay night” 시리즈는 리메이크 등 여러 버전 존재).

### 5.4 AniList API

* **API 종류**: AniList는 **GraphQL API**만을 공식 지원합니다. GraphQL은 단일 엔드포인트(`https://graphql.anilist.co` 등)에 쿼리를 보내는 방식이며, REST 대비 한 번 요청으로 다량의 관련 데이터를 효율적으로 가져올 수 있는 장점이 있습니다. AniList API 사용을 위해 별도의 키는 필요 없으나, 너무 많은 요청을 보내면 IP 제한이 있을 수 있어 권장 제한인 **분당 90회** 내로 사용해야 합니다. GraphQL 특성상, 요청당 데이터량에 따라 실제 부하가 결정되므로, **필요한 필드만 선택**하는 최적화가 중요합니다.

* **활용 방안**: AniList는 AniDB나 MAL과 데이터 중복이 많지만, **유저 관심도 데이터와 관계 데이터**(예: 비슷한 작품, 동일 스튜디오 작품, 제작진 정보)가 잘 되어 있습니다. 굳이 AniList까지 필요한가 고려할 수 있지만, *“있으면 좋은”* 기능 몇 가지를 위해 연동합니다:

  * **추천 작품**: AniList에는 특정 작품을 좋아하는 사람들이 좋아하는 다른 작품 리스트를 추출하는 쿼리를 작성할 수 있습니다. (직접적인 추천 API는 없지만, GraphQL로 사용자나 좋아요 데이터를 조합하는 식)
  * **트렌드**: 현재 인기있는 작품 (방영중인 애니 중 댓글수 상위 등) 데이터를 가져와 “요즘 화제작” 섹션을 꾸밀 수 있음.
  * **캐릭터 및 성우 정보**: AniList는 캐릭터와 성우 데이터도 제공하므로, 작품 상세 페이지에 부가 정보를 표시할 수 있음.

  우선 버전에서는 필수는 아니므로, AniList 플러그인은 **낮은 우선순위**로 개발하거나, 또는 AniList와 MAL 중 하나만 선택하려면 MAL(Jikan)을 우선하고 AniList는 보류할 수 있습니다.

* **구현**: Python에서 `gql`이나 `requests`로 GraphQL 쿼리를 보내면 됩니다. 쿼리 예시는 다음과 같습니다 (작품 검색 및 기본정보 조회):

  ```graphql
  query ($name: String) {
    Media(search: $name, type: ANIME) {
      id
      title {
        romaji
        english
        native
      }
      status
      episodes
      averageScore
      genres
    }
  }
  ```

  이를 호출하면 주어진 이름에 가장 가까운 애니메이션의 ID, 제목(로마지/영문/원문), 방영상태, 총 에피소드 수, 평균점수, 장르 목록을 얻을 수 있습니다. 이후 ID로 **추천** 쿼리를 날리거나 **트렌드** 쿼리를 날려볼 수 있습니다.

* **제한**: AniList API도 Abuse 시 차단될 수 있으므로, 필요한 경우 GraphQL 쿼리를 합쳐서 보내거나, 캐싱을 적극 활용합니다. AniList ID와 다른 DB의 ID 간 매핑은 공개된 것이 없지만, AniList의 Media 객체 안에 `idMal` 필드로 MAL ID가 제공됩니다. 따라서 MAL ID를 알면 AniList 쿼리를 통해 대응 AniList 데이터를 가져올 수도 있습니다. 이처럼 데이터 소스들 간의 연결고리를 최대한 활용하여 불필요한 검색을 줄입니다.

요약하면, **AniDB**는 정확한 식별과 기본 정보 제공자, **TMDB**는 시각적/스토리 정보 제공자, **MAL/AniList**는 평점/커뮤니티 정보 및 추천 기능의 보조 역할로 각각 포지셔닝하여, 여러 소스의 장점을 취합하는 방향으로 API 설계를 진행합니다.

## 6. 데이터베이스 스키마 상세 및 예시

앞서 4.4절에서 데이터베이스 스키마 예시를 제시하였으며, 여기서는 그 설계를 조금 더 상세히 설명합니다. 데이터베이스는 SQLite를 사용하며, SQLAlchemy ORM으로 매핑하여 다룹니다. 주요 엔티티(테이블)와 관계는 아래와 같습니다:

* **Series (시리즈 테이블)** – 애니메이션 작품 단위로 1개 레코드.

  * *주요 필드*: `id` (PK), `title`, `title_jp`, `year`, `season`, `anidb_id`, `mal_id`, `tmdb_id`, `average_score`, `genres`, `plot_summary` 등.
  * *설명*: 작품의 기본 정보와 외부 참조 ID들을 저장. `anidb_id` 등이 있는 경우 해당 ID로 API 재조회 없이 정보를 보강할 수 있음. `average_score`는 MAL이나 AniList의 평균 평점, `genres`는 장르 리스트 (콤마 구분 문자열 또는 별도 SeriesGenre 테이블로 정규화). `plot_summary`는 TMDB의 개요(한글이 있으면 한글로).

* **Episode (에피소드 테이블)** – 각 애니메이션의 화별 정보.

  * *주요 필드*: `id` (PK), `series_id` (FK, Series), `number` (에피소드 번호, 일부 SP나 번외는 0 또는 101 등으로 표시), `title` (에피소드 제목), `airdate` (방영일), `anidb_ep_id`, `file_count` (이 에피소드와 매칭된 파일 개수) 등.
  * *설명*: 에피소드 하나당 레코드. 보통 1화,2화,... 순으로 번호 매기며, 번호 대신 `code` 필드를 별도로 두어 “OVA”나 “SP”같이 특수코드를 저장할 수도 있음. `file_count`는 한 에피소드에 다수 파일이 링크될 수 있어서 (예: 자막 다른 버전), 이를 갯수로 표시하거나, 혹은 File 테이블에서 COUNT 할 수도 있음.

* **File (파일 테이블)** – 실제 디스크상의 파일 정보와 에피소드의 연결.

  * *주요 필드*: `id` (PK), `episode_id` (FK, Episode), `path` (파일 경로 또는 파일명), `ed2k_hash`, `size`, `quality` (화질, 해상도), `codec`, `last_modified` 등.
  * *설명*: 하나의 에피소드가 여러 파일로 존재할 수 있으므로 (예: 자막 다른 릴, 블루레이판 등), 각각을 구분해 관리. `path`는 정리 후의 위치로 업데이트 되며, 정리 전 원래 경로는 별도로 저장하지 않을 예정 (필요하다면 `original_path` 필드 둘 수도). `quality`나 `codec` 등은 FFmpeg 등으로 파일 분석하여 저장할 수 있으나, MVP에서는 생략 가능.

* **WatchHistory (시청 기록 테이블)** – 파일 단위 시청 기록.

  * *주요 필드*: `id` (PK), `file_id` (FK, File), `watched_at` (DATETIME), `duration` (INT, 재생 시간(초)), `completed` (BOOL).
  * *설명*: 한 파일(에피소드)을 시청한 기록을 남김. 한 에피소드를 여러 번 보면 여러 기록이 쌓일 수 있음. 최근 본 시각 등의 정보를 Episode나 Series에도 denormalization해서 가질 수 있음 (예: Series.last\_watched 등).

* **FavoriteSeries (즐겨찾기 테이블)** – 사용자가 즐겨찾기한 작품 목록.

  * *필드*: `id` (PK), `series_id` (FK, Series), `marked_at` (DATETIME).
  * *설명*: 다대다의 단순화 형태로, 유저가 한 명이므로 Series에 체크해도 되지만 확장성을 위해 별도 테이블로 둠. 현재는 단일 사용자 환경이므로 user\_id 같은 건 없음.

이상의 스키마로 기본적인 기능은 충실히 지원되며, 추후 기능 확장 시 테이블 추가 또는 컬럼 추가를 통해 대응합니다. 예를 들어 **인물(캐릭터/성우)** 테이블을 추가하거나, **시리즈 간 연관관계**(프리퀄/시퀄)를 저장하는 테이블을 둘 수도 있습니다. SQLite는 스키마 변경이 다소 제약이 있지만, SQLAlchemy를 통해 변경 스크립트를 적용하거나, 버전 업 시 마이그레이션 절차를 두는 등으로 대응 가능합니다.

특히 **성능** 면에서, 파일 수천개, 시리즈 수백 개 정도에서는 SQLite로도 충분히 커버됩니다. 테이블에 적절한 인덱스를 추가하여 (예: File.ed2k\_hash에 인덱스 -> 해시 조회 속도 향상, Episode.series\_id 인덱스 -> 시리즈 별 에피소드 나열 속도 향상 등) 쿼리 성능을 최적화합니다. 또한 ORM 사용 시 한번에 너무 많은 객체를 로딩하지 않도록 (lazy loading 활용) 유의합니다.

## 7. 플러그인 구조 및 확장 설계

메타데이터 수집과 파일 리네이밍 등을 유연하게 지원하기 위해 본 애플리케이션은 **플러그인 아키텍처**를 채택합니다. 플러그인은 **외부 API 연동**, **파일 이름 패턴 정의**, **커스텀 동작** 등을 손쉽게 추가하거나 변경할 수 있도록 합니다. 이 섹션에서는 플러그인의 구조와 동작 방식, 그리고 새로운 플러그인 등록 절차에 대해 설명합니다.

* **플러그인 인터페이스 설계**: 애플리케이션 코어는 플러그인에 대해 기대하는 동작을 **인터페이스 (또는 추상 베이스 클래스)** 형태로 정의합니다. 예를 들어 메타데이터 소스를 위한 `MetadataPlugin` 인터페이스를 정의하고, 여기에 `search_series(title) -> series_id` , `get_series_info(series_id) -> SeriesData`, `get_episode_info(series_id, ep_number) -> EpisodeData` 등의 메서드를 규정합니다. AniDB, TMDB, MAL, AniList 각 플러그인은 이 인터페이스를 구현하여, 코어가 동일한 방식으로 메서드를 호출하더라도 각각 알아서 해당 API를 호출하고 결과를 반환하도록 합니다. Python에서는 `abc` 모듈로 추상클래스를 정의하거나, 혹은 간단히 필요한 메서드 이름만 약속하여 duck typing으로 구현할 수도 있습니다.

```python
# 예시: MetadataPlugin 추상 클래스
from abc import ABC, abstractmethod

class MetadataPlugin(ABC):
    @abstractmethod
    def search_series(self, title:str, year:int=None) -> dict:
        """제목 (및 선택적 연도)을 받아 시리즈 정보 반환 (없으면 None)."""
        pass

    @abstractmethod
    def get_series_info(self, id:str) -> dict:
        """시리즈 ID를 받아 상세 정보를 딕셔너리로 반환."""
        pass

    @abstractmethod
    def get_episode_info(self, series_id:str, ep_number:int) -> dict:
        """특정 시리즈의 에피소드 번호에 해당하는 에피소드 정보 반환."""
        pass
```

위 인터페이스를 구현한 AniDBPlugin, TMDBPlugin 등 클래스를 각각 만들고, 필요한 필드를 딕셔너리나 dataclass 형태로 반환하도록 합니다. 반환된 딕셔너리는 공통 키를 가지며, 예를 들어 `{'id': 'TMDB:12345', 'title': '진격의 거인', 'episodes': [...], 'year': 2013, 'season': 2, ...}` 이런 식으로 통일합니다. 통합은 코어에서 담당합니다.

* **플러그인 로딩 메커니즘**: 플러그인은 **동적 로딩**이 가능하도록 설계합니다. 이를 위해 두 가지 방법을 고려합니다:

  1. **엔트리 포인트 기반 로딩**: Python 패키지 배포 메커니즘에서 setup.py의 `entry_points`를 사용하면, 특정 그룹의 플러그인을 자동으로 인식할 수 있습니다. 예를 들어 `entry_points={'anime_manager.plugins': ['AniDB=plugins.anidb:AniDBPlugin']}` 식으로 작성하고, 코어에서 `importlib.metadata.entry_points()`로 불러오면 설치된 플러그인 모듈들을 가져올 수 있습니다. 이 방식은 플러그인을 독립적인 패키지로 배포할 수 있게 해줍니다.
  2. **플러그인 디렉토리 스캔**: 애플리케이션 폴더 내 `plugins` 디렉토리에 있는 모든 `*.py` 파일을 임포트하여 일정 네이밍 규칙 (예: `XxxPlugin` 클래스)으로 플러그인을 찾습니다. 예를 들어 `plugins/anidb_plugin.py` 내에 `AniDBPlugin` 클래스가 있고 `MetadataPlugin`을 상속한다면 이를 등록합니다. 이 방식은 구현이 간단하나, 별도 배포된 플러그인을 사용자가 추가하려면 해당 폴더에 직접 파일을 넣어야 합니다.

  초기 버전에서는 간단한 **디렉토리 스캔 방식**을 채택하고, 추후 사용자/3rd-party 플러그인 생태계가 필요할 정도로 발전하면 엔트리 포인트 방식을 병행합니다.

* **플러그인 등록 및 설정**: 어떤 플러그인을 사용할지 설정할 수 있도록, 환경설정 파일(e.g., `config.yaml`)이나 GUI 설정 화면에서 플러그인 On/Off 및 우선순위를 관리합니다. 예를 들어 TMDB와 AniList 둘 다 시리즈 정보를 가져올 수 있지만, **시리즈 설명은 TMDB 우선, 평점은 MAL 우선** 등의 정책을 정합니다. 이러한 설정은 코어의 메타데이터 통합 로직에 반영되어, 각 필드별 우선 소스를 결정짓거나, 혹은 첫 성공 응답을 준 플러그인 것으로 설정하는 등 동작하게 합니다. 또한 AniDBPlugin처럼 필수적으로 항상 켜져야 하는 플러그인은 끌 수 없도록 할 수 있습니다.

* **플러그인 간 의존성**: 이상적으로 플러그인은 서로 독립적으로 동작하지만, 약간의 연계는 고려합니다. 예를 들어 AniDBPlugin이 파일 해시를 통해 `series_id`를 반환하면, TMDBPlugin은 그 시리즈명을 사용하여 TMDB 검색을 하는 식으로 **연쇄 호출**이 일어납니다. 이를 코어 로직에서 조율해도 되지만, 플러그인 내부에서 다른 플러그인을 호출하지 않도록 합니다 (의존성 엉킴 방지). 대신 코어가 흐름 제어를 합니다. 즉, AniDBPlugin.identify() → 결과로 시리즈명 얻음 → TMDBPlugin.search\_series(시리즈명) → TMDBPlugin.get\_series\_info(ID) → AniListPlugin.get\_series\_info(ID) ... 이런 순서를 코어에서 orchestrate합니다.

* **파일 정리 플러그인**: 플러그인 아키텍처는 메타데이터 뿐 아니라, **파일 이름 패턴이나 정리 방식**을 커스터마이즈하는 데에도 적용할 수 있습니다. 예를 들어 사용자가 특별한 폴더 구조를 원한다면, `OrganizerPlugin` 형태로 플러그인을 만들어 해당 로직을 구현하게 할 수 있습니다. 기본 구조(연도/분기)는 내장으로 제공하고, 고급 사용자들은 자신의 스크립트를 만들어 플러그인으로 추가할 수 있게 하는 구상입니다. 다만 초기 버전에서는 복잡도를 줄이기 위해 파일 정리 로직은 고정하고, 메타데이터 부분만 플러그인화합니다.

* **테스트 및 샌드박스**: 플러그인은 외부 API를 다루므로, 오용 시 예측하지 못한 동작이나 과도한 요청을 보낼 위험도 있습니다. 따라서 플러그인 별로 **사용량 제한**을 코어에서 감시하고, 에러 발생 시 코어가 예외를 처리하여 전체 프로그램이 안정적으로 (크래시 없이) 대응할 수 있도록 해야 합니다. 각 플러그인의 메서드 호출은 try-except로 감싸서 실패한 플러그인을 건너뛰고 로그를 남기며, 사용자에게는 해당 소스에서 데이터를 못 가져왔다는 정보만 알리면 됩니다.

플러그인 구조를 통해 **유연성**과 **확장성**을 확보할 수 있습니다. 새로운 애니메이션 데이터 소스(API)가 등장하거나, 기존 API의 변경이 있을 때, 이 구조 안에 쉽게 편입할 수 있을 것입니다. 예를 들어 국내 사용자들을 위해 **애니메이션 자막 팀 데이터**나 **국내 방영 정보 API**를 플러그인으로 추가하는 것도 가능해질 것입니다.

## 8. 테스트 전략

개발한 애플리케이션이 올바르고 견고하게 동작하도록 하기 위해 **다양한 수준의 테스트**를 수행합니다. 테스트는 유닛 테스트, 통합 테스트, UI 테스트, 성능 테스트로 나눠 진행합니다.

* **유닛 테스트 (Unit Tests)**: 각각의 모듈 (해시 계산, 개별 플러그인, DB 매퍼, 파일 이름 변환 등)에 대해 단위 테스트를 작성합니다. Python의 `pytest` 프레임워크를 사용하여, 예를 들어:

  * ED2K 해시 계산 함수에 known-value 테스트 (작은 파일의 ED2K 해시를 수작업으로 구해놓고 함수 출력과 비교).
  * 파일 이름 파싱 로직 테스트 (여러 형태의 파일명을 입력하여 시리즈명과 화수를 정확히 뽑는지 검증).
  * DB ORM 모델 테스트 (객체 저장/조회 동작 검증, 제약 조건 테스트).
  * 플러그인 메서드 테스트: 실제 API 호출을 직접 하지 않고 \*\*모의 객체(Mock)\*\*나 **vcr.py** 같은 HTTP 인터셉터를 써서 정해진 응답을 돌려주도록 한 후, 파싱 로직이 잘 작동하는지 확인합니다. (API 키 등이 필요한 경우 별도 환경변수 세팅 후 진행하거나, Public한 테스트 ID로 한정)

* **통합 테스트 (Integration Tests)**: 전체 시스템의 주요 시나리오를 통합적으로 테스트합니다. 예를 들어, \*\*시나리오: “특정 폴더에 있는 파일들 정리”\*\*의 경우:

  1. 테스트용 폴더에 여러 파일을 준비 (의도적으로 다양한 케이스: AniDB에 존재하는 파일, 이상한 이름 파일, 중복 파일 등).
  2. 애플리케이션의 코어 로직을 해당 폴더에 대해 실행.
  3. 결과로 생성된 DB와 폴더 구조를 확인:

     * DB에 모든 시리즈/에피소드/파일이 예상대로 입력되었는지.
     * 실제 파일이 옮겨졌는지, 이름이 올바른지.
     * 로그나 메시지에 오류는 없는지.
       이러한 통합 테스트는 실제 API에 연결해서 수행할 수도 있지만, 자동화 환경에서 외부 API에 너무 의존하면 오작동할 수 있으므로, 가능하면 **캐시된 응답**이나 **로컬 서버**를 흉내내어 진행합니다. (예: AniDB UDP 서버를 Mock으로 흉내내거나, TMDB API 응답 JSON을 저장해 사용)

* **GUI 테스트**: GUI는 자동화 테스트가 어려운 부분이 있으나, Qt(PySide6)의 경우 Signal/Slot을 이용해 시뮬레이션이 가능하고, 또 Selenium 같은 툴로 UI를 조작할 수도 있습니다. 우선은 개발 단계에서 **수동 테스트**를 위주로 하고, 중요 로직은 View와 분리되어 있으므로 유닛/통합 테스트로 신뢰성을 담보합니다. 이후 안정화 단계에서 Qt의 `QTest` 모듈 등을 활용해 가상으로 버튼 클릭, 리스트 선택 등을 시뮬레이션하고 결과 상태(DB나 로그 변화)를 검증하는 자동화도 검토합니다.

* **성능 및 부하 테스트**: 라이브러리에 수천 개의 파일이 있을 때 초기 스캔 및 정리 시간이 얼마나 걸리는지 측정합니다. 예를 들어 1000개의 파일(약 1TB 데이터)에 대해 정리 작업을 돌렸을 때, 해시 계산에 수 분, API 호출에 수 분 등 전체 소요 시간을 추산하고, 메모리 사용량도 모니터링합니다. SQLite 접근이 병목되지 않도록 인덱스 튜닝 여부를 여기서 판단합니다. 또한 Watchdog로 지속 감시할 때 CPU 점유율이 미미한지, GUI 스레드와 작업 스레드 간 데드락이나 리소스 경합이 없는지도 확인합니다.

* **사용자 인수 테스트 (UAT)**: 내부적으로 충분히 테스트한 후, 베타 버전을 소수의 사용자(예: 개발팀 내 혹은 관심있는 지인)에 제공하여 **실제 시나리오 테스트**를 받습니다. 사용자의 실제 애니메이션 폴더를 대상으로 실행해보고, 예상치 못한 상황(특이한 파일명, 네트워크 불안정 등)에서의 문제를 피드백받아 수정합니다. 특히 한국 사용자의 패턴 (한글 파일명, 멀티 자막 등)에 특화된 조정도 이 단계에서 반영합니다.

* **테스트 환경**: 개발 중에는 Windows 10/11 환경에서 테스트하며, CI(Continuous Integration) 환경에서는 Windows Runner를 사용해 pytest를 돌립니다. CI에서 실제 API 호출 테스트는 키 관리 문제로 제외하거나 read-only 테스트만 수행하고, 로컬에서 통합 테스트는 주기적으로 수동으로 돌려봅니다.

테스트를 충분히 거침으로써, 릴리스 시 주요 기능들이 의도대로 작동하고, 오류 상황에서도 프로그램이 안정적으로 (크래시 없이) 대응할 수 있도록 합니다. 특히 파일 이동/삭제와 같은 **파괴적인 작업의 신뢰성**이 핵심이므로, 이를 위한 시뮬레이션 모드와 백업 기능을 실제 테스트해 검증하는 것이 중요합니다.

## 9. 배포 및 유지보수 전략

마지막으로, 완성된 프로그램을 사용자에게 배포하고 향후 유지보수/업데이트하는 전략입니다. Windows 전용 애플리케이션이므로 Windows 환경에 최적화된 배포 방식을 고려합니다.

* **배포 형식**: Python으로 개발되었지만, **Standalone 실행 파일 (.exe)** 형태로 배포하여 사용자가 Python 환경을 직접 건드릴 필요 없도록 합니다. `PyInstaller`를 사용하여 모든 의존 라이브러리와 Python 인터프리터를 포함한 실행 파일을 생성합니다. PyInstaller를 통해 single-folder 모드(여러 파일 묶음)나 one-file 모드(압축된 단일 exe)로 만들 수 있는데, 용량은 증가해도 편의성을 위해 **일체형 실행 파일**로 제공하는 것을 고려합니다. 이 때 VLC나 MPV 등의 외부 프로그램은 사용자에게 별도 설치를 요구할 수 있으므로, 만약 portable VLC를 함께 번들링하려면 라이선스 검토가 필요합니다 (VLC is LGPL, bundling is allowed as long as license is included).

* **인스톨러 제공**: 사용 편의를 위해 Inno Setup이나 NSIS를 이용해 \*\*Windows 설치 프로그램 (Installer)\*\*을 제공할 수도 있습니다. 설치 프로그램은 Start Menu 등록, 바탕화면 아이콘, 폴더 연결(우클릭 메뉴 “이 폴더를 애니메이션 정리하기” 같은) 등을 포함할 수 있습니다. 하지만 처음에는 포터블 실행 파일만 제공하고, 피드백에 따라 인스톨러를 마련합니다.

* **업데이트 배포**: 정기적인 업데이트를 위해 **자동 업데이트 기능**을 고려합니다. 앱 자체에 업데이트 체크 기능을 넣어, GitHub Releases나 서버에 버전 정보를 조회하고 새 버전이 있으면 사용자에게 알려 다운로드/적용하게 할 수 있습니다. `pip`로 배포하지 않는 독립 실행 앱이므로, 이 기능은 고객 만족도에 영향을 줍니다. 구현은 어렵지 않으나, 초기 버전에서는 수동 업데이트로 안내하고, 사용자가 중요 문제를 제기하면 패치 버전을 배포하는 방식으로 진행합니다.

* **로그와 오류 보고**: 배포 버전에서는 상세 로그를 남기되, 사용자에게는 가급적 노출하지 않습니다. 치명 오류 발생 시 (예외 처리되지 못한 에러 등) 프로그램이 죽지 않고 오류 상황을 알려주며, **오류 리포트**를 생성하여 개발자에게 보낼 수 있도록 합니다. 예를 들어 오류 내용을 텍스트로 저장해두고, 사용자가 “오류 보고” 버튼을 누르면 GitHub 이슈 페이지나 이메일로 보낼 수 있게 하는 겁니다. 이를 통해 현장에서 발견되는 버그를 신속히 수집합니다.

* **성능 모니터링**: 배포 후 사용자들의 라이브러리 규모에 따라 성능 이슈가 표면화될 수 있습니다. 이를 위해 옵션으로 **디버그 모드**를 제공하여, 작업 단위 시간 측정 로그를 남기게 할 수 있습니다. 큰 폴더에서 느리다는 피드백이 오면, 디버그 모드 실행을 안내하여 어디서 병목이 있는지 파악합니다. 필요하면 특정 연산(예: 해시 계산)에 C 구현 또는 JIT 최적화(PyPy 등)를 적용하는 식으로 튜닝합니다.

* **기능 추가와 플러그인 업데이트**: 새로운 애니메이션 DB 서비스가 나오거나, 기존 API의 변경이 있을 때 (예: AniDB API 스펙 변경, MAL 사이트 개편) 대응이 필요합니다. 플러그인 구조 덕분에 해당 부분만 수정하여 업데이트 버전을 내면 되지만, API 변경에 프로그램이 갑자기 일부 기능이 멈출 수 있다는 점을 사용자에게 공지하고, 빠르게 업데이트를 제공하는 것이 중요합니다. GitHub 리포지토리를 운영하여 이슈 트래킹 및 사용자 요청 기능을 수렴하고, 오픈소스로 공개하여 외부 기여를 받을 수도 있습니다.

* **사용자 가이드와 문서**: 배포 시 **간단한 사용 설명서**를 함께 제공합니다. 예를 들어 README.md 또는 PDF 매뉴얼로 설치 방법, 초기 설정 (API 키 입력 등), 기본 사용법(폴더 선택 -> 정리 버튼) 등을 도식과 함께 설명합니다. 또한 각 기능별 세부 옵션(예: 정리 규칙 커스터마이즈, 즐겨찾기, 통계 보는 법 등)도 문서화합니다. 이 문서는 한글로 제공하되, UI 용어와 기술명은 영어 병기하여 이해를 돕습니다.

* **라이선스와 감사**: 사용된 오픈소스 라이브러리들의 라이선스를 검토하여, 배포물에 license 파일을 포함합니다. 특히 PySide6 (LGPL), watchdog (Apache), requests (Apache) 등은 비교적 간단하지만, 만약 우리가 가져다 쓴 코드 조각이나 번들링한 프로그램이 있으면 그에 맞는 조치를 합니다. 상업적 활용이 아니더라도 오픈소스 의무를 지킵니다.

* **향후 계획**: 유지보수 측면에서, 앞으로 추가 구현하고자 하는 기능들(예: 모바일 연동, 웹 UI 추가, Cross-platform 지원 등)을 고려한 코드 구조 유연성을 유지합니다. 윈도우 전용으로 시작하지만, 논리코드와 인터페이스를 분리해두면 PySide6를 사용하여 macOS/Linux 빌드도 나중에 시도할 수 있습니다. 또는 Electron으로 전환하는 경우를 대비해 백엔드(API 통신, DB)는 모듈화 해두고, 프론트엔드는 갈아끼울 수 있도록 합니다.

마지막으로, 배포 후에도 사용자의 목소리를 지속적으로 듣고 개선을 이어나가는 것이 중요합니다. 이를 위해 사용자 커뮤니티 (예: 디스코드, 오픈 카카오톡, 깃허브 Discussions 등)를 운영하여 피드백 통로를 열어둡니다. 안정적인 배포와 적극적인 유지보수를 통해 본 애플리케이션이 애니메이션 감상자들에게 신뢰받는 툴이 되도록 노력하겠습니다.
